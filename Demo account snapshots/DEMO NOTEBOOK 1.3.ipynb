{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bee82c",
   "metadata": {},
   "source": [
    "# Notebooks contents & summary\n",
    "\n",
    "Running this notebook will give you the equivalent of the snapshots and scans in the DemoAccount.\n",
    "\n",
    "### SET-UP\n",
    " - import \n",
    " - login to dashboard\n",
    " - open project\n",
    "\n",
    "\n",
    "### SNAPSHOT 1: xgboost, pre-configured model\n",
    " - SCANS:\n",
    "  - accuracy \n",
    "  - bias metrics\n",
    "\n",
    "\n",
    "### SNAPSHOT 2: xgboost, pre-configured model\n",
    " - SCANS:\n",
    "  - bias sources \n",
    "  - accuracy \n",
    "  - bias metrics\n",
    "  - leakage\n",
    "    \n",
    "### MODEL FIXES \n",
    "\n",
    "### SNAPSHOT 3: xgboost, new version, pre-configured model\n",
    " - SCANS:\n",
    "  - bias sources \n",
    "  - accuracy \n",
    "  - bias metrics \n",
    "  - leakage\n",
    "\n",
    "\n",
    "### SNAPSHOT 4: xgboost, new version, pre-configured model, added dataset for previous time period\n",
    " - SCANS:\n",
    "  - bias sources \n",
    "  - accuracy \n",
    "  - bias metrics \n",
    "  - leakage\n",
    "  - feature drift \n",
    "\t\n",
    "### SNAPSHOT 5: user defined model  \n",
    " - SCANS: \n",
    "  - accuracy \n",
    "  - bias metrics \n",
    "  - leakage\n",
    " \n",
    "\n",
    "### SNAPSHOT 6: production \n",
    "  - SCANS: \n",
    "   - feature drift \n",
    "   - applicable bias metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f8f3c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff524b3",
   "metadata": {},
   "source": [
    "# SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4d5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba75bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dashboard supplied updated license information)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Connection successful. Projects and pipelines will be displayed in the dashboard. ðŸ˜€"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import login as etiq_login\n",
    "etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ec9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Can enumerate all available projects\n",
    "all_projects = etiq.projects.get_all_projects()\n",
    "print(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Demo Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f7699",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72d34b",
   "metadata": {},
   "source": [
    "# SNAPSHOT 1: xgboost, pre-configured model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e966368",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "\n",
    "First, we'll be encoding the categorical features found in this dataset.\n",
    "\n",
    "Second, we'll log the dataset to Etiq.\n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation.\n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE.\n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example.\n",
    "\n",
    "Remember: This is an example only. The use case for the majority of scans in Etiq is that you log the model to Etiq once you have the sample that you'll be training on. Usually this sample will have numeric features only as otherwise you will not be able to use it in with the majority of supported libraries training methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede7b01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe126d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq.transforms import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72e5aa",
   "metadata": {},
   "source": [
    "## Loading the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ab3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.8, 0.1, 0.1],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.7, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.2],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_bias_sources': {'auto': True},\n",
       " 'scan_leakage': {'leakage_threshold': 0.85},\n",
       " 'scan_drift_metrics': {'thresholds': {'psi': [0.0, 0.15],\n",
       "   'kolmogorov_smirnov': [0.05, 1.0]},\n",
       "  'drift_measures': ['kolmogorov_smirnov', 'psi']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX: Make per-project.\n",
    "etiq.load_config(\"./config_demo_snapshots.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cdbcd7",
   "metadata": {},
   "source": [
    "## Logging the snapshot to Etiq \n",
    "\n",
    "This can happen at any point in the pipeline and through a variety of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load your dataset\n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "\n",
    "from etiq.model import DefaultXGBoostClassifier\n",
    "# Load our model\n",
    "model = DefaultXGBoostClassifier()\n",
    "\n",
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Snapshot 1\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107538d",
   "metadata": {},
   "source": [
    "## Start scanning for errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48df62",
   "metadata": {},
   "source": [
    "## Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432f8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0557:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0557:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0557:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0557:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0557:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_below_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7f7e4b1e8160&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy_above_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7f7e4b1e8160&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true_pos_rate_below_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7f7e4b1e81f0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{all}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_pos_rate_above_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7f7e4b1e81f0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true_neg_rate_below_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7f7e4b1e8280&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true_neg_rate_above_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7f7e4b1e8280&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                                      metric  \\\n",
       "0       accuracy_below_threshold       <function accuracy at 0x7f7e4b1e8160>   \n",
       "1       accuracy_above_threshold       <function accuracy at 0x7f7e4b1e8160>   \n",
       "2  true_pos_rate_below_threshold  <function true_pos_rate at 0x7f7e4b1e81f0>   \n",
       "3  true_pos_rate_above_threshold  <function true_pos_rate at 0x7f7e4b1e81f0>   \n",
       "4  true_neg_rate_below_threshold  <function true_neg_rate at 0x7f7e4b1e8280>   \n",
       "5  true_neg_rate_above_threshold  <function true_neg_rate at 0x7f7e4b1e8280>   \n",
       "\n",
       "  measure features segments  total_issues_tested  issues_found   threshold  \n",
       "0    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "1    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "2    None       {}    {all}                    1             1  [0.7, 1.0]  \n",
       "3    None       {}       {}                    1             0  [0.7, 1.0]  \n",
       "4    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "5    None       {}       {}                    1             0  [0.6, 1.0]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719e37e",
   "metadata": {},
   "source": [
    "## Bias Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3545fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0680:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0680:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0680:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0680:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0680:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_metrics\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830e8675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb33e5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29057cdd",
   "metadata": {},
   "source": [
    "# Leakage Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba17b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f82e2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.DataPipeline0530:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0530:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0530:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0530:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0530:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0681:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0681:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0681:Start Phase IdentifyFeatureLeakPipeline0673\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0673:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0673:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0673:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0681:Completed Phase IdentifyFeatureLeakPipeline0673\n",
      "INFO:etiq.pipeline.DebiasPipeline0681:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_leakage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9b7ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_leakage_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function corrcoef at 0x7f7eb807cb80&gt;</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0.85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demographic_leakage_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function corrcoef at 0x7f7eb807cb80&gt;</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0.85)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name metric                                measure  \\\n",
       "0       target_leakage_issue   None  <function corrcoef at 0x7f7eb807cb80>   \n",
       "1  demographic_leakage_issue   None  <function corrcoef at 0x7f7eb807cb80>   \n",
       "\n",
       "  features segments  total_issues_tested  issues_found  threshold  \n",
       "0       {}       {}                   13             0  (0, 0.85)  \n",
       "1       {}       {}                   13             0  (0, 0.85)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31c168",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d9c858",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1190c54",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b5a20",
   "metadata": {},
   "source": [
    "# SNAPSHOT 2: xgboost, pre-configured  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed58547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your dataset\n",
    "#For bias sources you need to add some specific syntax at the moment \n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "dl = etiq.dataset_loader.DatasetLoader(data=data_encoded, label='income', bias_params=dataset_loader.bias_params,\n",
    "                   train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars,\n",
    "                   cont_col=cont_vars, names_col = data_encoded.columns.values)\n",
    "\n",
    "from etiq.model import DefaultXGBoostClassifier\n",
    "# Load our model\n",
    "model = DefaultXGBoostClassifier()\n",
    "\n",
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Snapshot 2\", dataset=dl.initial_dataset, model=model, bias_params=dataset_loader.bias_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa3ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0975:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0975:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0975:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0975:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0975:Completed pipeline\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0593:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0593:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0593:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0593:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0593:Completed pipeline\n",
      "WARNING:etiq.pipeline.DataPipeline0366:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0366:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0366:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0366:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0366:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0790:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0790:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0790:Start Phase IdentifyFeatureLeakPipeline0704\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0704:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0704:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0704:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0790:Completed Phase IdentifyFeatureLeakPipeline0704\n",
      "INFO:etiq.pipeline.DebiasPipeline0790:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#Bias metrics scans, accuracy metrics scans, data leakage scans\n",
    "\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_metrics()\n",
    "\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_leakage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe2b53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.DataPipeline0693:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0693:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0693:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0693:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0693:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0187:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0187:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0187:Start Phase IdentifyPipeline0701\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking proxy for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking correlation for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0701:Checking Skew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raluca/etiq/python_core/etiq/metrics.py:52: RuntimeWarning: Mean of empty slice.\n",
      "  return {'accuracy': round((pred == label).mean(), 2)}\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/raluca/etiq/python_core/etiq/metrics.py:52: RuntimeWarning: Mean of empty slice.\n",
      "  return {'accuracy': round((pred == label).mean(), 2)}\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/raluca/etiq/python_core/etiq/metrics.py:52: RuntimeWarning: Mean of empty slice.\n",
      "  return {'accuracy': round((pred == label).mean(), 2)}\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/raluca/etiq/python_core/etiq/metrics.py:52: RuntimeWarning: Mean of empty slice.\n",
      "  return {'accuracy': round((pred == label).mean(), 2)}\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/raluca/etiq/python_core/etiq/metrics.py:52: RuntimeWarning: Mean of empty slice.\n",
      "  return {'accuracy': round((pred == label).mean(), 2)}\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/scipy-1.7.2-py3.8-linux-x86_64.egg/scipy/stats/_entropy.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2683: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2542: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2542: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.IdentifyPipeline0701:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0187:Completed Phase IdentifyPipeline0701\n",
      "INFO:etiq.pipeline.DebiasPipeline0187:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0187:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df218e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>feature</th>\n",
       "      <th>segment</th>\n",
       "      <th>measure</th>\n",
       "      <th>measure_value</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>relationship</td>\n",
       "      <td>20.0</td>\n",
       "      <td>&lt;function corrcoef at 0x7f7eb807cb80&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>occupation</td>\n",
       "      <td>20.0</td>\n",
       "      <td>&lt;function corrcoef at 0x7f7eb807cb80&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f7e4b1e84c0&gt;</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f7e4b1e84c0&gt;</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f7e4b1e84c0&gt;</td>\n",
       "      <td>0.209402</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name       feature  segment  \\\n",
       "0         low_unpriv_sample          None      0.0   \n",
       "1         low_unpriv_sample          None      1.0   \n",
       "2         low_unpriv_sample          None      2.0   \n",
       "3         low_unpriv_sample          None      3.0   \n",
       "4         low_unpriv_sample          None      4.0   \n",
       "..                      ...           ...      ...   \n",
       "197       correlation_issue  relationship     20.0   \n",
       "198       correlation_issue    occupation     20.0   \n",
       "199  limited_features_issue          None      3.0   \n",
       "200  limited_features_issue          None      4.0   \n",
       "201  limited_features_issue          None     10.0   \n",
       "\n",
       "                                   measure  measure_value  \\\n",
       "0                                     None            NaN   \n",
       "1                                     None            NaN   \n",
       "2                                     None            NaN   \n",
       "3                                     None            NaN   \n",
       "4                                     None            NaN   \n",
       "..                                     ...            ...   \n",
       "197  <function corrcoef at 0x7f7eb807cb80>            NaN   \n",
       "198  <function corrcoef at 0x7f7eb807cb80>            NaN   \n",
       "199                                   None            NaN   \n",
       "200                                   None            NaN   \n",
       "201                                   None            NaN   \n",
       "\n",
       "                                             metric  metric_value   threshold  \n",
       "0                                              None           NaN  (0.0, 0.8)  \n",
       "1                                              None           NaN  (0.0, 0.8)  \n",
       "2                                              None           NaN  (0.0, 0.8)  \n",
       "3                                              None           NaN  (0.0, 0.8)  \n",
       "4                                              None           NaN  (0.0, 0.8)  \n",
       "..                                              ...           ...         ...  \n",
       "197                                            None           NaN  (0.0, 0.2)  \n",
       "198                                            None           NaN  (0.0, 0.2)  \n",
       "199  <function equal_opportunity at 0x7f7e4b1e84c0>      0.325000  (0.0, 0.2)  \n",
       "200  <function equal_opportunity at 0x7f7e4b1e84c0>      0.234568  (0.0, 0.2)  \n",
       "201  <function equal_opportunity at 0x7f7e4b1e84c0>      0.209402  (0.0, 0.2)  \n",
       "\n",
       "[202 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f4bac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{5, 6, 7, 19, 20}</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{0, 1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skewed_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skewed_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{10, 4}</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>proxy_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function corrcoef at 0x7f7eb807cb80&gt;</td>\n",
       "      <td>{relationship}</td>\n",
       "      <td>{3, 4, 8, 10, 12, 16, 17, 18}</td>\n",
       "      <td>273</td>\n",
       "      <td>8</td>\n",
       "      <td>(0.0, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function corrcoef at 0x7f7eb807cb80&gt;</td>\n",
       "      <td>{marital-status, educational-num, age, native-...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>273</td>\n",
       "      <td>168</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>low_volume_group</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>(1000, inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f7e4b1e84c0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{10.0, 3.0, 4.0}</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                          metric  \\\n",
       "0          missing_sample                                            None   \n",
       "1       low_unpriv_sample                                            None   \n",
       "2         low_priv_sample                                            None   \n",
       "3      skewed_priv_sample                                            None   \n",
       "4    skewed_unpriv_sample                                            None   \n",
       "5             proxy_issue                                            None   \n",
       "6       correlation_issue                                            None   \n",
       "7        low_volume_group                                            None   \n",
       "8  limited_features_issue  <function equal_opportunity at 0x7f7e4b1e84c0>   \n",
       "\n",
       "                                 measure  \\\n",
       "0                                   None   \n",
       "1                                   None   \n",
       "2                                   None   \n",
       "3                                   None   \n",
       "4                                   None   \n",
       "5  <function corrcoef at 0x7f7eb807cb80>   \n",
       "6  <function corrcoef at 0x7f7eb807cb80>   \n",
       "7                                   None   \n",
       "8                                   None   \n",
       "\n",
       "                                            features  \\\n",
       "0                                                 {}   \n",
       "1                                                 {}   \n",
       "2                                                 {}   \n",
       "3                                                 {}   \n",
       "4                                                 {}   \n",
       "5                                     {relationship}   \n",
       "6  {marital-status, educational-num, age, native-...   \n",
       "7                                                 {}   \n",
       "8                                                 {}   \n",
       "\n",
       "                                            segments  total_issues_tested  \\\n",
       "0                                  {5, 6, 7, 19, 20}                   21   \n",
       "1  {0, 1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, ...                   16   \n",
       "2                                                 {}                   16   \n",
       "3                                                 {}                   14   \n",
       "4                                            {10, 4}                   16   \n",
       "5                      {3, 4, 8, 10, 12, 16, 17, 18}                  273   \n",
       "6  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...                  273   \n",
       "7                                                 {}                   21   \n",
       "8                                   {10.0, 3.0, 4.0}                   21   \n",
       "\n",
       "   issues_found    threshold  \n",
       "0             5   (0.0, 0.0)  \n",
       "1            16   (0.0, 0.8)  \n",
       "2             0   (0.0, 0.8)  \n",
       "3             0   (0.0, 0.2)  \n",
       "4             2   (0.0, 0.2)  \n",
       "5             8   (0.0, 0.5)  \n",
       "6           168   (0.0, 0.2)  \n",
       "7             0  (1000, inf)  \n",
       "8             3   (0.0, 0.2)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc229f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b68372f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>business_rule</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>`native-country` == 39 and `occupation` == 6</td>\n",
       "      <td>[False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>`native-country` == 39 and `occupation` == 1 and `education` == 11</td>\n",
       "      <td>[False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>`native-country` == 39 and `occupation` == 14 and `workclass` == 4</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>`native-country` == 39 and `occupation` == 7 and `workclass` == 4 and `education` == 11</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>`native-country` == 39 and `occupation` == 13</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>`occupation` == 4 and `race` == 4 and `native-country` == 39 and `workclass` == 4 and `relationship` == 0</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>`occupation` == 3 and `workclass` == 4 and `marital-status` == 2 and `native-country` == 39 and `relationship` == 0</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>`occupation` == 10 and `native-country` == 39 and `marital-status` == 2 and `relationship` == 0</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>`native-country` == 39 and `education` == 11 and `race` == 2</td>\n",
       "      <td>[False, False, True, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>`native-country` == 39 and `education` == 11 and `race` == 4 and `occupation` == 3</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>`native-country` == 39 and `education` == 11 and `race` == 4 and `occupation` == 12</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>`native-country` == 39 and `education` == 1 and `workclass` == 4</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>`native-country` == 39 and `workclass` == 4 and `race` == 4 and `occupation` == 3 and `marital-status` == 2</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>`native-country` == 39 and `workclass` == 4 and `race` == 4 and `occupation` == 14</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>`native-country` == 39 and `occupation` == 1 and `education` == 15</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>`native-country` == 39 and `education` == 15 and `race` == 4 and `occupation` == 1</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>`native-country` == 39 and `education` == 11 and `occupation` == 7</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>`native-country` == 39 and `marital-status` == 2 and `occupation` == 3 and `education` == 11</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>all</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>`relationship` == 0</td>\n",
       "      <td>[False, True, True, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, True, False, True, False, False, True, False, False, True, False, False, True, False, True, False, True, False, True, False, False, True, True, False, False, False, True, False, True, True, False, False, False, False, False, False, False, True, False, True, True, False, False, False, False, False, False, True, False, False, True, False, False, True, False, False, True, True, True, False, True, False, True, False, False, False, False, True, True, False, True, True, False, False, True, False, False, True, True, True, False, True, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>`relationship` == 5</td>\n",
       "      <td>[False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "5      5   \n",
       "6      6   \n",
       "7      7   \n",
       "8      8   \n",
       "9      9   \n",
       "10    10   \n",
       "11    11   \n",
       "12    12   \n",
       "13    13   \n",
       "14    14   \n",
       "15    15   \n",
       "16    16   \n",
       "17    17   \n",
       "18    18   \n",
       "19    19   \n",
       "20    20   \n",
       "\n",
       "                                                                                                          business_rule  \\\n",
       "0                                                                          `native-country` == 39 and `occupation` == 6   \n",
       "1                                                    `native-country` == 39 and `occupation` == 1 and `education` == 11   \n",
       "2                                                    `native-country` == 39 and `occupation` == 14 and `workclass` == 4   \n",
       "3                               `native-country` == 39 and `occupation` == 7 and `workclass` == 4 and `education` == 11   \n",
       "4                                                                         `native-country` == 39 and `occupation` == 13   \n",
       "5             `occupation` == 4 and `race` == 4 and `native-country` == 39 and `workclass` == 4 and `relationship` == 0   \n",
       "6   `occupation` == 3 and `workclass` == 4 and `marital-status` == 2 and `native-country` == 39 and `relationship` == 0   \n",
       "7                       `occupation` == 10 and `native-country` == 39 and `marital-status` == 2 and `relationship` == 0   \n",
       "8                                                          `native-country` == 39 and `education` == 11 and `race` == 2   \n",
       "9                                    `native-country` == 39 and `education` == 11 and `race` == 4 and `occupation` == 3   \n",
       "10                                  `native-country` == 39 and `education` == 11 and `race` == 4 and `occupation` == 12   \n",
       "11                                                     `native-country` == 39 and `education` == 1 and `workclass` == 4   \n",
       "12          `native-country` == 39 and `workclass` == 4 and `race` == 4 and `occupation` == 3 and `marital-status` == 2   \n",
       "13                                   `native-country` == 39 and `workclass` == 4 and `race` == 4 and `occupation` == 14   \n",
       "14                                                   `native-country` == 39 and `occupation` == 1 and `education` == 15   \n",
       "15                                   `native-country` == 39 and `education` == 15 and `race` == 4 and `occupation` == 1   \n",
       "16                                                   `native-country` == 39 and `education` == 11 and `occupation` == 7   \n",
       "17                         `native-country` == 39 and `marital-status` == 2 and `occupation` == 3 and `education` == 11   \n",
       "18                                                                                                                  all   \n",
       "19                                                                                                  `relationship` == 0   \n",
       "20                                                                                                  `relationship` == 5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                mask  \n",
       "0    [False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "1     [False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "2         [False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "3     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "4         [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "5     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "6     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       "7      [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, ...]  \n",
       "8       [False, False, True, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "9      [False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       "10  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "11  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "12    [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       "13     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "14   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "15   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "16    [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       "17   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       "18                                                                                                     [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, ...]  \n",
       "19                                      [False, True, True, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, True, False, True, False, False, True, False, False, True, False, False, True, False, True, False, True, False, True, False, False, True, True, False, False, False, True, False, True, True, False, False, False, False, False, False, False, True, False, True, True, False, False, False, False, False, False, True, False, False, True, False, False, True, False, False, True, True, True, False, True, False, True, False, False, False, False, True, True, False, True, True, False, False, True, False, False, True, True, True, False, True, ...]  \n",
       "20       [False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, ...]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804fd4f5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3c8b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2ac68",
   "metadata": {},
   "source": [
    "# SNAPSHOT 3: xgboost, new version, pre-configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45130c",
   "metadata": {},
   "source": [
    "For this version we will remove relationship which was found as a proxy across most segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef40b09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initial dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b482664e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct  Black    Male             0             0   \n",
       "1    Farming-fishing  White    Male             0             0   \n",
       "2    Protective-serv  White    Male             0             0   \n",
       "3  Machine-op-inspct  Black    Male          7688             0   \n",
       "4                  ?  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove relationship\n",
    "\n",
    "data_clean = data.drop('relationship', axis = 1)\n",
    "\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a7a2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq.transforms import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data_clean.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data_clean[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data_clean.index, inplace=True)\n",
    "data_encoded = pd.concat([data_clean.loc[:, cont_vars], data_encoded], axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4cd96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your dataset\n",
    "#For bias sources you need to add some specific syntax at the moment \n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "dl = etiq.dataset_loader.DatasetLoader(data=data_encoded, label='income', bias_params=dataset_loader.bias_params,\n",
    "                   train_valid_test_splits=[0.8, 0.1, 0.1], cat_col=cat_vars,\n",
    "                   cont_col=cont_vars, names_col = data_encoded.columns.values)\n",
    "\n",
    "from etiq.model import DefaultXGBoostClassifier\n",
    "# Load our model\n",
    "model = DefaultXGBoostClassifier()\n",
    "\n",
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Snapshot 3\", dataset=dl.initial_dataset, model=model, bias_params=dataset_loader.bias_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a4ab762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0687:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0687:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0687:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0687:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0687:Completed pipeline\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0121:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0121:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0121:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0121:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0121:Completed pipeline\n",
      "WARNING:etiq.pipeline.DataPipeline0869:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0869:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0869:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0869:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0869:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0069:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0069:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0069:Start Phase IdentifyFeatureLeakPipeline0528\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0528:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0528:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0528:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0069:Completed Phase IdentifyFeatureLeakPipeline0528\n",
      "INFO:etiq.pipeline.DebiasPipeline0069:Completed pipeline\n",
      "WARNING:etiq.pipeline.DataPipeline0044:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0044:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0044:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0044:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0044:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0472:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0472:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0472:Start Phase IdentifyPipeline0780\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking proxy for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking correlation for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0780:Checking Skew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.IdentifyPipeline0780:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0472:Completed Phase IdentifyPipeline0780\n",
      "INFO:etiq.pipeline.DebiasPipeline0472:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0472:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    name  \\\n",
       " 0      0   \n",
       " 1      1   \n",
       " 2      2   \n",
       " 3      3   \n",
       " 4      4   \n",
       " 5      5   \n",
       " 6      6   \n",
       " 7      7   \n",
       " 8      8   \n",
       " 9      9   \n",
       " 10    10   \n",
       " 11    11   \n",
       " 12    12   \n",
       " 13    13   \n",
       " 14    14   \n",
       " 15    15   \n",
       " 16    16   \n",
       " 17    17   \n",
       " 18    18   \n",
       " \n",
       "                                                                                                   business_rule  \\\n",
       " 0                                                                  `native-country` == 39 and `occupation` == 6   \n",
       " 1                                            `native-country` == 39 and `occupation` == 1 and `education` == 11   \n",
       " 2                                            `native-country` == 39 and `occupation` == 14 and `workclass` == 4   \n",
       " 3                       `native-country` == 39 and `occupation` == 7 and `workclass` == 4 and `education` == 11   \n",
       " 4                                                                 `native-country` == 39 and `occupation` == 13   \n",
       " 5                   `native-country` == 39 and `marital-status` == 2 and `workclass` == 4 and `occupation` == 3   \n",
       " 6                                                  `native-country` == 39 and `education` == 11 and `race` == 2   \n",
       " 7                            `native-country` == 39 and `education` == 11 and `race` == 4 and `occupation` == 3   \n",
       " 8                           `native-country` == 39 and `education` == 11 and `race` == 4 and `occupation` == 12   \n",
       " 9                                              `native-country` == 39 and `education` == 1 and `workclass` == 4   \n",
       " 10  `native-country` == 39 and `workclass` == 4 and `race` == 4 and `occupation` == 3 and `marital-status` == 2   \n",
       " 11                           `native-country` == 39 and `workclass` == 4 and `race` == 4 and `occupation` == 14   \n",
       " 12                                           `native-country` == 39 and `occupation` == 1 and `education` == 15   \n",
       " 13                           `native-country` == 39 and `education` == 15 and `race` == 4 and `occupation` == 1   \n",
       " 14                                           `native-country` == 39 and `education` == 11 and `occupation` == 7   \n",
       " 15     `marital-status` == 2 and `native-country` == 39 and `occupation` == 3 and `race` == 4 and `age` <= 37.0   \n",
       " 16      `marital-status` == 2 and `native-country` == 39 and `occupation` == 3 and `race` == 4 and `age` > 37.0   \n",
       " 17                 `native-country` == 39 and `marital-status` == 2 and `occupation` == 3 and `education` == 11   \n",
       " 18                                                                                       `native-country` == 39   \n",
       " \n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 mask  \n",
       " 0    [False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 1     [False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 2         [False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 3     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 4         [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 5     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       " 6       [False, False, True, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 7      [False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       " 8   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 9   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 10    [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       " 11     [False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 12   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 13   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 14    [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 15    [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       " 16  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...]  \n",
       " 17   [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, ...]  \n",
       " 18                                                                                             [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, ...]  ,\n",
       "                        name         feature  segment  \\\n",
       " 0         low_unpriv_sample            None      0.0   \n",
       " 1         low_unpriv_sample            None      1.0   \n",
       " 2         low_unpriv_sample            None      2.0   \n",
       " 3         low_unpriv_sample            None      3.0   \n",
       " 4         low_unpriv_sample            None      4.0   \n",
       " ..                      ...             ...      ...   \n",
       " 135       correlation_issue      occupation     17.0   \n",
       " 136       correlation_issue  native-country     18.0   \n",
       " 137  limited_features_issue            None      3.0   \n",
       " 138  limited_features_issue            None      4.0   \n",
       " 139  limited_features_issue            None      8.0   \n",
       " \n",
       "                                    measure  measure_value  \\\n",
       " 0                                     None            NaN   \n",
       " 1                                     None            NaN   \n",
       " 2                                     None            NaN   \n",
       " 3                                     None            NaN   \n",
       " 4                                     None            NaN   \n",
       " ..                                     ...            ...   \n",
       " 135  <function corrcoef at 0x7f7eb807cb80>            NaN   \n",
       " 136  <function corrcoef at 0x7f7eb807cb80>            NaN   \n",
       " 137                                   None            NaN   \n",
       " 138                                   None            NaN   \n",
       " 139                                   None            NaN   \n",
       " \n",
       "                                              metric  metric_value   threshold  \n",
       " 0                                              None           NaN  (0.0, 0.8)  \n",
       " 1                                              None           NaN  (0.0, 0.8)  \n",
       " 2                                              None           NaN  (0.0, 0.8)  \n",
       " 3                                              None           NaN  (0.0, 0.8)  \n",
       " 4                                              None           NaN  (0.0, 0.8)  \n",
       " ..                                              ...           ...         ...  \n",
       " 135                                            None           NaN  (0.0, 0.2)  \n",
       " 136                                            None           NaN  (0.0, 0.2)  \n",
       " 137  <function equal_opportunity at 0x7f7e4b1e84c0>      0.350000  (0.0, 0.2)  \n",
       " 138  <function equal_opportunity at 0x7f7e4b1e84c0>      0.306878  (0.0, 0.2)  \n",
       " 139  <function equal_opportunity at 0x7f7e4b1e84c0>      0.228632  (0.0, 0.2)  \n",
       " \n",
       " [140 rows x 8 columns],\n",
       "                      name                                          metric  \\\n",
       " 0          missing_sample                                            None   \n",
       " 1       low_unpriv_sample                                            None   \n",
       " 2         low_priv_sample                                            None   \n",
       " 3      skewed_priv_sample                                            None   \n",
       " 4    skewed_unpriv_sample                                            None   \n",
       " 5             proxy_issue                                            None   \n",
       " 6       correlation_issue                                            None   \n",
       " 7        low_volume_group                                            None   \n",
       " 8  limited_features_issue  <function equal_opportunity at 0x7f7e4b1e84c0>   \n",
       " \n",
       "                                  measure  \\\n",
       " 0                                   None   \n",
       " 1                                   None   \n",
       " 2                                   None   \n",
       " 3                                   None   \n",
       " 4                                   None   \n",
       " 5  <function corrcoef at 0x7f7eb807cb80>   \n",
       " 6  <function corrcoef at 0x7f7eb807cb80>   \n",
       " 7                                   None   \n",
       " 8                                   None   \n",
       " \n",
       "                                                                                                                                              features  \\\n",
       " 0                                                                                                                                                  {}   \n",
       " 1                                                                                                                                                  {}   \n",
       " 2                                                                                                                                                  {}   \n",
       " 3                                                                                                                                                  {}   \n",
       " 4                                                                                                                                                  {}   \n",
       " 5                                                                                                                                                  {}   \n",
       " 6  {marital-status, educational-num, age, native-country, hours-per-week, capital-loss, workclass, capital-gain, education, race, fnlwgt, occupation}   \n",
       " 7                                                                                                                                                  {}   \n",
       " 8                                                                                                                                                  {}   \n",
       " \n",
       "                                                              segments  \\\n",
       " 0                                                                  {}   \n",
       " 1  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}   \n",
       " 2                                                                  {}   \n",
       " 3                                                                  {}   \n",
       " 4                                                          {8, 18, 4}   \n",
       " 5                                                                  {}   \n",
       " 6  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}   \n",
       " 7                                                                  {}   \n",
       " 8                                                     {8.0, 3.0, 4.0}   \n",
       " \n",
       "    total_issues_tested  issues_found    threshold  \n",
       " 0                   19             0   (0.0, 0.0)  \n",
       " 1                   19            19   (0.0, 0.8)  \n",
       " 2                   19             0   (0.0, 0.8)  \n",
       " 3                   16             0   (0.0, 0.2)  \n",
       " 4                   19             3   (0.0, 0.2)  \n",
       " 5                  228             0   (0.0, 0.5)  \n",
       " 6                  228           115   (0.0, 0.2)  \n",
       " 7                   19             0  (1000, inf)  \n",
       " 8                   19             3   (0.0, 0.2)  )"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bias metrics scans, accuracy metrics scans, data leakage scans\n",
    "\n",
    "\n",
    "snapshot.scan_accuracy_metrics()\n",
    "\n",
    "snapshot.scan_bias_metrics()\n",
    "\n",
    "snapshot.scan_leakage()\n",
    "\n",
    "snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d560117",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2aeeea",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55c248",
   "metadata": {},
   "source": [
    "# SNAPSHOT 4, xgboost, pre-configured, + dataset from previous period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f636cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>226802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>89814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>336951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>160323</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>103497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  educational-num  fnlwgt  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   25                7  226802             0             0            48.0   \n",
       "1   38                9   89814             0             0            60.0   \n",
       "2   28               12  336951             0             0            48.0   \n",
       "3   44               10  160323          7688             0            48.0   \n",
       "4   18               10  103497             0             0            36.0   \n",
       "\n",
       "   marital-status  gender  native-country  workclass  education  income  race  \\\n",
       "0               4       1              39          4          1       0     2   \n",
       "1               2       1              39          4         11       0     4   \n",
       "2               2       1              39          2          7       1     4   \n",
       "3               2       1              39          4         15       1     2   \n",
       "4               4       0              39          0         15       0     4   \n",
       "\n",
       "   occupation  \n",
       "0           7  \n",
       "1           5  \n",
       "2          11  \n",
       "3           7  \n",
       "4           0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Because we are still in build stage, this drift scan is to check whether there are differences between periods\n",
    "# Create the \"drifted\" dataset from the pre-period - this is not part of the logging library\n",
    "yesterday_dataset_df = data_encoded.copy()\n",
    "yesterday_dataset_df[\"hours-per-week\"] = yesterday_dataset_df[\"hours-per-week\"].multiply(1.2)\n",
    "\n",
    "yesterday_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81b42a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with the comparison data\n",
    "#dataset_s = etiq.SimpleDatasetBuilder.from_dataframe(data_encoded, target_feature='income').build()\n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "\n",
    "\n",
    "# Create a dataset with the data\n",
    "yesterday_dataset_s = etiq.SimpleDatasetBuilder.from_dataframe(yesterday_dataset_df, target_feature='income').build()\n",
    "\n",
    "from etiq.model import DefaultXGBoostClassifier\n",
    "# Load our model\n",
    "model = DefaultXGBoostClassifier()\n",
    "\n",
    "\n",
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Snapshot 4\", dataset=dataset_loader.initial_dataset, comparison_dataset=yesterday_dataset_s, model=model, bias_params=dataset_loader.bias_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d00a490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0217:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0217:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0217:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0217:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0217:Completed pipeline\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0415:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0415:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0415:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0415:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0415:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  name business_rule  \\\n",
       " 0  all           all   \n",
       " \n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             mask  \n",
       " 0  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, ...]  ,\n",
       "                                  name feature segment measure  measure_value  \\\n",
       " 0  demographic_parity_above_threshold    None     all    None            NaN   \n",
       " \n",
       "                                             metric  metric_value   threshold  \n",
       " 0  <function demographic_parity at 0x7f7e4b1e8310>      0.208174  [0.0, 0.2]  ,\n",
       "                                   name  \\\n",
       " 0   demographic_parity_below_threshold   \n",
       " 1   demographic_parity_above_threshold   \n",
       " 2       equal_odds_tpr_below_threshold   \n",
       " 3       equal_odds_tpr_above_threshold   \n",
       " 4       equal_odds_tnr_below_threshold   \n",
       " 5       equal_odds_tnr_above_threshold   \n",
       " 6    equal_opportunity_below_threshold   \n",
       " 7    equal_opportunity_above_threshold   \n",
       " 8  individual_fairness_below_threshold   \n",
       " 9  individual_fairness_above_threshold   \n",
       " \n",
       "                                              metric measure features segments  \\\n",
       " 0   <function demographic_parity at 0x7f7e4b1e8310>    None       {}       {}   \n",
       " 1   <function demographic_parity at 0x7f7e4b1e8310>    None       {}    {all}   \n",
       " 2       <function equal_odds_tpr at 0x7f7e4b1e83a0>    None       {}       {}   \n",
       " 3       <function equal_odds_tpr at 0x7f7e4b1e83a0>    None       {}       {}   \n",
       " 4       <function equal_odds_tnr at 0x7f7e4b1e8430>    None       {}       {}   \n",
       " 5       <function equal_odds_tnr at 0x7f7e4b1e8430>    None       {}       {}   \n",
       " 6    <function equal_opportunity at 0x7f7e4b1e84c0>    None       {}       {}   \n",
       " 7    <function equal_opportunity at 0x7f7e4b1e84c0>    None       {}       {}   \n",
       " 8  <function individual_fairness at 0x7f7e4b1e8700>    None       {}       {}   \n",
       " 9  <function individual_fairness at 0x7f7e4b1e8700>    None       {}       {}   \n",
       " \n",
       "    total_issues_tested  issues_found   threshold  \n",
       " 0                    1             0  [0.0, 0.2]  \n",
       " 1                    1             1  [0.0, 0.2]  \n",
       " 2                    1             0  [0.0, 0.2]  \n",
       " 3                    1             0  [0.0, 0.2]  \n",
       " 4                    1             0  [0.0, 0.2]  \n",
       " 5                    1             0  [0.0, 0.2]  \n",
       " 6                    1             0  [0.0, 0.2]  \n",
       " 7                    1             0  [0.0, 0.2]  \n",
       " 8                    1             0  [0.0, 0.2]  \n",
       " 9                    1             0  [0.0, 0.2]  )"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.scan_accuracy_metrics()\n",
    "\n",
    "snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6930551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.DriftPipeline0245:Starting pipeline\n",
      "INFO:etiq.pipeline.DriftPipeline0245:Calculated drift measures.\n",
      "INFO:etiq.pipeline.DriftPipeline0245:Identifying drift measure issues.\n",
      "INFO:etiq.pipeline.DriftPipeline0245:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_drift_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ae4e3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>feature</th>\n",
       "      <th>segment</th>\n",
       "      <th>measure</th>\n",
       "      <th>measure_value</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_drift_above_threshold</td>\n",
       "      <td>hours-per-week</td>\n",
       "      <td>all</td>\n",
       "      <td>&lt;function psi at 0x7f7e4a652550&gt;</td>\n",
       "      <td>2.087093</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_drift_below_threshold</td>\n",
       "      <td>hours-per-week</td>\n",
       "      <td>all</td>\n",
       "      <td>&lt;function kolmogorov_smirnov at 0x7f7e4a6525e0&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.05, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name         feature segment  \\\n",
       "0  feature_drift_above_threshold  hours-per-week     all   \n",
       "1  feature_drift_below_threshold  hours-per-week     all   \n",
       "\n",
       "                                           measure  measure_value metric  \\\n",
       "0                 <function psi at 0x7f7e4a652550>       2.087093   None   \n",
       "1  <function kolmogorov_smirnov at 0x7f7e4a6525e0>       0.000000   None   \n",
       "\n",
       "   metric_value    threshold  \n",
       "0           NaN  [0.0, 0.15]  \n",
       "1           NaN  [0.05, 1.0]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4804ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_drift_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function psi at 0x7f7e4a652550&gt;</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_drift_above_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function psi at 0x7f7e4a652550&gt;</td>\n",
       "      <td>{hours-per-week}</td>\n",
       "      <td>{all}</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_drift_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function kolmogorov_smirnov at 0x7f7e4a6525e0&gt;</td>\n",
       "      <td>{hours-per-week}</td>\n",
       "      <td>{all}</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.05, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_drift_above_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function kolmogorov_smirnov at 0x7f7e4a6525e0&gt;</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.05, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name metric  \\\n",
       "0  feature_drift_below_threshold   None   \n",
       "1  feature_drift_above_threshold   None   \n",
       "2  feature_drift_below_threshold   None   \n",
       "3  feature_drift_above_threshold   None   \n",
       "\n",
       "                                           measure          features segments  \\\n",
       "0                 <function psi at 0x7f7e4a652550>                {}       {}   \n",
       "1                 <function psi at 0x7f7e4a652550>  {hours-per-week}    {all}   \n",
       "2  <function kolmogorov_smirnov at 0x7f7e4a6525e0>  {hours-per-week}    {all}   \n",
       "3  <function kolmogorov_smirnov at 0x7f7e4a6525e0>                {}       {}   \n",
       "\n",
       "   total_issues_tested  issues_found    threshold  \n",
       "0                   12             0  [0.0, 0.15]  \n",
       "1                   12             1  [0.0, 0.15]  \n",
       "2                   12             1  [0.05, 1.0]  \n",
       "3                   12             0  [0.05, 1.0]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b8feb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14de77",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ead395",
   "metadata": {},
   "source": [
    "# SNAPSHOT 5, already trained model, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96378ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9855230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3aef7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training/testing/validation datasets\n",
    "\n",
    "# separate into train/validate/test dataset of sizes 80%/10%/10% as percetages of the initial data\n",
    "data_remaining, test = train_test_split(data_encoded, test_size=0.1)\n",
    "train, valid = train_test_split(data_remaining, test_size=0.1112)\n",
    "\n",
    "# because we don't want to train on protected attributes or labels to be predicted, \n",
    "# let's remove these columns from the training dataset\n",
    "protected_train = train['gender'].copy() # gender is a protected attribute\n",
    "y_train = train['income'].copy() # labels we're going to train the model to predict\n",
    "x_train = train.drop(columns=['gender','income'])\n",
    "protected_valid = valid['gender'].copy() \n",
    "y_valid = valid['income'].copy() \n",
    "x_valid = valid.drop(columns=['gender','income'])\n",
    "protected_test = test['gender'].copy() \n",
    "y_test = test['income'].copy()\n",
    "x_test = test.drop(columns=['gender','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "818b3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model to predict 'income'\n",
    "\n",
    "standard_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=4)    \n",
    "model_fit = standard_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1b990c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the training dataset : 90.07 %\n",
      "Model accuracy on the validation dataset : 87.77 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = standard_model.predict(x_train)\n",
    "y_valid_pred = standard_model.predict(x_valid)\n",
    "print('Model accuracy on the training dataset :', \n",
    "      round(100 * accuracy_score(y_train, y_train_pred),2),'%') # round the score to 2 digits  \n",
    "\n",
    "print('Model accuracy on the validation dataset :', \n",
    "      round(100 * accuracy_score(y_valid, y_valid_pred),2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a76dc",
   "metadata": {},
   "source": [
    "## Log config, dataset and model to Etiq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a6d3a",
   "metadata": {},
   "source": [
    "For already trained models make sure you only you use a sample you held out. \n",
    "\n",
    "As you don't want any retraining of the model to occur, set your train_valid_test split to [0.0, 1.0, 0.0]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44d278f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.0, 1.0, 0.0],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.8],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_leakage': {'leakage_threshold': 0.85}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq.load_config(\"./config_already_trained.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a03eb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "\n",
    "#log your dataset\n",
    "\n",
    "dataset_loader = etiq.dataset(test)\n",
    "\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_architecture=standard_model, model_fitted=model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff243883",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = project.snapshots.create(name=\"Snapshot 5\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cb0f6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0779:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0779:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0779:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0779:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0779:Completed pipeline\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0825:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0825:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0825:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0825:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0825:Completed pipeline\n",
      "WARNING:etiq.pipeline.DataPipeline0327:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0327:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0327:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0327:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0327:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0227:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0227:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0227:Start Phase IdentifyFeatureLeakPipeline0943\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0943:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0943:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyFeatureLeakPipeline0943:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0227:Completed Phase IdentifyFeatureLeakPipeline0943\n",
      "INFO:etiq.pipeline.DebiasPipeline0227:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   name     business_rule  \\\n",
       " 0     0  kmeans segment 0   \n",
       " \n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             mask  \n",
       " 0  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, ...]  ,\n",
       " Empty DataFrame\n",
       " Columns: []\n",
       " Index: [],\n",
       "                         name metric                                measure  \\\n",
       " 0       target_leakage_issue   None  <function corrcoef at 0x7f7eb807cb80>   \n",
       " 1  demographic_leakage_issue   None  <function corrcoef at 0x7f7eb807cb80>   \n",
       " \n",
       "   features segments  total_issues_tested  issues_found  threshold  \n",
       " 0       {}       {}                   13             0  (0, 0.85)  \n",
       " 1       {}       {}                   13             0  (0, 0.85)  )"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.scan_accuracy_metrics()\n",
    "\n",
    "snapshot.scan_bias_metrics()\n",
    "\n",
    "\n",
    "snapshot.scan_leakage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546fdbd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da569de",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42599999",
   "metadata": {},
   "source": [
    "# SNAPSHOT 6, in-production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe17e3",
   "metadata": {},
   "source": [
    "To run scans in production you can use a similar set-up like in pre-production. \n",
    "     - for drift - you will need your current feature/label dataset and a comparison dataset (as per the pre-production example above)\n",
    "     - for bias - you will need your model and your feature/label dataset that you have scored \n",
    "     \n",
    "At the moment functionality will not allow to record actuals separtely, but we are working on it. This means that to run scans which use the actuals (accuracy, a good chunk of the bias metrics scans, target and concept drift), you will have to create your dataset to include the actuals. To log it to etiq the actual will be the 'label' parameter in your config.\n",
    " \n",
    "This example is just for illustration purposes as you will not be running production scans from a jupyter notebook. \n",
    "Etiq can be used with orchestration and model registry tools. Please email us: info@etiq.ai for help with using Etiq with your toolset and for online models. We will be adding demos on how to use Etiq with Airflow and MLflow shortly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f251e4",
   "metadata": {},
   "source": [
    "## Log dataset, comparison dataset, model, config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8be571",
   "metadata": {},
   "source": [
    "For the dataset we will use yesterday and today's datasets set-up earlier in the notebook, but any time window will work - depends on your scoring frequency. \n",
    "\n",
    "For model: we will use the model we've trained at the previous step. \n",
    "\n",
    "For config we will use a config that has scans achievable in production without the actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f33c8e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.0, 1.0, 0.0],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.8],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_drift_metrics': {'thresholds': {'psi': [0.0, 0.15],\n",
       "   'kolmogorov_smirnov': [0.05, 1.0]},\n",
       "  'drift_measures': ['kolmogorov_smirnov', 'psi']}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq.load_config(\"./config_production.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11827c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a dataset with the comparison data\n",
    "#dataset_s = etiq.SimpleDatasetBuilder.from_dataframe(data_encoded, target_feature='income').build()\n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "\n",
    "# Create a dataset with the data\n",
    "yesterday_dataset_s = etiq.SimpleDatasetBuilder.from_dataframe(yesterday_dataset_df, target_feature='income').build()\n",
    "\n",
    "\n",
    "# Use the already trained model from the previous step\n",
    "from etiq import Model\n",
    "model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "# Creating a snapshot, label it as PRODUCTION (snapshots are labelled Pre-Production) by default\n",
    "from etiq import SnapshotStage\n",
    "snapshot = project.snapshots.create(name=\"Snapshot 6\", dataset=dataset_loader.initial_dataset, comparison_dataset=yesterday_dataset_s, model=model, bias_params=dataset_loader.bias_params, stage=SnapshotStage.PRODUCTION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04efad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0717:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0717:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0717:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0717:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0717:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  name business_rule mask\n",
       " 0  all           all   [],\n",
       " Empty DataFrame\n",
       " Columns: []\n",
       " Index: [],\n",
       "                                   name  \\\n",
       " 0   demographic_parity_below_threshold   \n",
       " 1   demographic_parity_above_threshold   \n",
       " 2       equal_odds_tpr_below_threshold   \n",
       " 3       equal_odds_tpr_above_threshold   \n",
       " 4       equal_odds_tnr_below_threshold   \n",
       " 5       equal_odds_tnr_above_threshold   \n",
       " 6    equal_opportunity_below_threshold   \n",
       " 7    equal_opportunity_above_threshold   \n",
       " 8  individual_fairness_below_threshold   \n",
       " 9  individual_fairness_above_threshold   \n",
       " \n",
       "                                              metric measure features segments  \\\n",
       " 0   <function demographic_parity at 0x7f7e4b1e8310>    None       {}       {}   \n",
       " 1   <function demographic_parity at 0x7f7e4b1e8310>    None       {}       {}   \n",
       " 2       <function equal_odds_tpr at 0x7f7e4b1e83a0>    None       {}       {}   \n",
       " 3       <function equal_odds_tpr at 0x7f7e4b1e83a0>    None       {}       {}   \n",
       " 4       <function equal_odds_tnr at 0x7f7e4b1e8430>    None       {}       {}   \n",
       " 5       <function equal_odds_tnr at 0x7f7e4b1e8430>    None       {}       {}   \n",
       " 6    <function equal_opportunity at 0x7f7e4b1e84c0>    None       {}       {}   \n",
       " 7    <function equal_opportunity at 0x7f7e4b1e84c0>    None       {}       {}   \n",
       " 8  <function individual_fairness at 0x7f7e4b1e8700>    None       {}       {}   \n",
       " 9  <function individual_fairness at 0x7f7e4b1e8700>    None       {}       {}   \n",
       " \n",
       "    total_issues_tested  issues_found   threshold  \n",
       " 0                    1             0  [0.0, 0.2]  \n",
       " 1                    1             0  [0.0, 0.2]  \n",
       " 2                    1             0  [0.0, 0.2]  \n",
       " 3                    1             0  [0.0, 0.2]  \n",
       " 4                    1             0  [0.0, 0.2]  \n",
       " 5                    1             0  [0.0, 0.2]  \n",
       " 6                    1             0  [0.0, 0.2]  \n",
       " 7                    1             0  [0.0, 0.2]  \n",
       " 8                    1             0  [0.0, 0.8]  \n",
       " 9                    1             0  [0.0, 0.8]  )"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.scan_bias_metrics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc292fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.DriftPipeline0399:Starting pipeline\n",
      "INFO:etiq.pipeline.DriftPipeline0399:Calculated drift measures.\n",
      "INFO:etiq.pipeline.DriftPipeline0399:Identifying drift measure issues.\n",
      "INFO:etiq.pipeline.DriftPipeline0399:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  name business_rule  \\\n",
       " 0  all           all   \n",
       " \n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             mask  \n",
       " 0  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, ...]  ,\n",
       "                             name         feature segment  \\\n",
       " 0  feature_drift_above_threshold  hours-per-week     all   \n",
       " 1  feature_drift_below_threshold  hours-per-week     all   \n",
       " \n",
       "                                            measure  measure_value metric  \\\n",
       " 0                 <function psi at 0x7f7e4a652550>       2.087093   None   \n",
       " 1  <function kolmogorov_smirnov at 0x7f7e4a6525e0>       0.000000   None   \n",
       " \n",
       "    metric_value    threshold  \n",
       " 0           NaN  [0.0, 0.15]  \n",
       " 1           NaN  [0.05, 1.0]  ,\n",
       "                             name metric  \\\n",
       " 0  feature_drift_below_threshold   None   \n",
       " 1  feature_drift_above_threshold   None   \n",
       " 2  feature_drift_below_threshold   None   \n",
       " 3  feature_drift_above_threshold   None   \n",
       " \n",
       "                                            measure          features segments  \\\n",
       " 0                 <function psi at 0x7f7e4a652550>                {}       {}   \n",
       " 1                 <function psi at 0x7f7e4a652550>  {hours-per-week}    {all}   \n",
       " 2  <function kolmogorov_smirnov at 0x7f7e4a6525e0>  {hours-per-week}    {all}   \n",
       " 3  <function kolmogorov_smirnov at 0x7f7e4a6525e0>                {}       {}   \n",
       " \n",
       "    total_issues_tested  issues_found    threshold  \n",
       " 0                   12             0  [0.0, 0.15]  \n",
       " 1                   12             1  [0.0, 0.15]  \n",
       " 2                   12             1  [0.05, 1.0]  \n",
       " 3                   12             0  [0.05, 1.0]  )"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.scan_drift_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e90f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e447c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961aa60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
