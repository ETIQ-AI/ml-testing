{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ec1eb3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29557b",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "### Example dataset & model\n",
    "\n",
    "\n",
    "  4. Example model: using Adult dataset, predicts income above/below 50K \n",
    "  \n",
    "### Create a snapshot \n",
    "\n",
    "  5. Log dataset & model \n",
    "  \n",
    "  6. Load a config file\n",
    "  \n",
    "  6. Create a snapshot \n",
    "  \n",
    "  \n",
    "### Scan your snapshot \n",
    "  \n",
    "  7. Run a scan \n",
    "  \n",
    "  8. Retrieve results\n",
    "  \n",
    "  \n",
    "### Example other scans "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d96e3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff524b3",
   "metadata": {},
   "source": [
    "# Quickstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4d5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba75bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dashboard supplied updated license information)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Connection successful. Projects and pipelines will be displayed in the dashboard. ðŸ˜€"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import login as etiq_login\n",
    "etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ec9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Can enumerate all available projects\n",
    "all_projects = etiq.projects.get_all_projects()\n",
    "print(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Demo Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f999bc",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72d34b",
   "metadata": {},
   "source": [
    "# Example dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e966368",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "First, we'll be encoding the categorical features found in this dataset. \n",
    "\n",
    "Second, we'll log the dataset to Etiq. \n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation. \n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE. \n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example. \n",
    "\n",
    "Remember: This is an example only. The use case for the majority of scans in Etiq is that you log the model to Etiq once you have the sample that you'll be training on. Usually this sample will have numeric features only as otherwise you will not be able to use it in with the majority of supported libraries training methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede7b01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe126d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq.transforms import LabelEncoder\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c6c29",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72e5aa",
   "metadata": {},
   "source": [
    "# Create a snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f86dd5",
   "metadata": {},
   "source": [
    "## Log dataset & model to Etiq \n",
    "\n",
    "For example of how to use Etiq on already-built models check out our other notebooks. \n",
    "\n",
    "In this example we will use a pre-loaded Etiq xgboost wrapper to get you started faster. \n",
    "But in your usual use case you will probably scan a model you already built. \n",
    "\n",
    "If you are planning to use this in production, not just pre-production get in touch with us. We will release integration demos shortly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f5b6d",
   "metadata": {},
   "source": [
    "## Loading the config file \n",
    "\n",
    "The config is where you can set-up the scans you want, and the thresholds outside of which Etiq finds a problem. In the config you input relevant parameters (e.g. for bias/fairness scans you'll have to tell Etiq which feature is a demographic and which value represents a protected group). \n",
    "For more details on the config just check the documentation. You can upload these config files from wherever you want. We provide examples in the Demo repo with each notebook.   \n",
    "\n",
    "The config gets stored in the database so you can have a log and version control. You will need to load the config before you log the dataset and the model as Etiq will check if it has enough information to process them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ab3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.8, 0.1, 0.1],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.75, 1.0],\n",
       "   'true_neg_rate': [0.7, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.2, 10],\n",
       "   'demographic_parity': [0.2, 10],\n",
       "   'equal_odds_tnr': [0.2, 10]}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "etiq.load_config(\"./config_bias.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cdbcd7",
   "metadata": {},
   "source": [
    "## Logging the snapshot to Etiq \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load your dataset\n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "\n",
    "from etiq.model import DefaultXGBoostClassifier\n",
    "# Load our model\n",
    "model = DefaultXGBoostClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585950e",
   "metadata": {},
   "source": [
    "## Creating a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f723ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = project.snapshots.create(name=\"Test Snapshot\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bb4c4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107538d",
   "metadata": {},
   "source": [
    "# Run scans\n",
    "\n",
    "You can run multiple scans for snapshot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719e37e",
   "metadata": {},
   "source": [
    "## Bias Metrics & Bias Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3545fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0714:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0714:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0714:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0714:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0714:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_metrics\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea0744",
   "metadata": {},
   "source": [
    "\n",
    "Scan results are fairly self-explanatory. To help with root cause analysis we give information on:\n",
    "\n",
    "1) each issue tested as part of the scan \n",
    "\n",
    "2) if the issue was found\n",
    "\n",
    "3) what is the metric the test was based on and what is the value of the metric \n",
    "\n",
    "4) what are the thresholds outside which an issue is detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830e8675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>feature</th>\n",
       "      <th>segment</th>\n",
       "      <th>measure</th>\n",
       "      <th>measure_value</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demographic_parity_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function demographic_parity at 0x7fae018a21f0&gt;</td>\n",
       "      <td>0.186333</td>\n",
       "      <td>[0.2, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equal_odds_tpr_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function equal_odds_tpr at 0x7fae018a2280&gt;</td>\n",
       "      <td>0.102702</td>\n",
       "      <td>(0.5, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equal_odds_tnr_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function equal_odds_tnr at 0x7fae018a2310&gt;</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>[0.2, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equal_opportunity_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7fae018a23a0&gt;</td>\n",
       "      <td>0.102702</td>\n",
       "      <td>[0.2, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>individual_fairness_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;function individual_fairness at 0x7fae018a25e0&gt;</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>(0.5, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name feature segment measure  measure_value  \\\n",
       "0   demographic_parity_below_threshold    None     all    None            NaN   \n",
       "1       equal_odds_tpr_below_threshold    None     all    None            NaN   \n",
       "2       equal_odds_tnr_below_threshold    None     all    None            NaN   \n",
       "3    equal_opportunity_below_threshold    None     all    None            NaN   \n",
       "4  individual_fairness_below_threshold    None     all    None            NaN   \n",
       "\n",
       "                                             metric  metric_value   threshold  \n",
       "0   <function demographic_parity at 0x7fae018a21f0>      0.186333   [0.2, 10]  \n",
       "1       <function equal_odds_tpr at 0x7fae018a2280>      0.102702  (0.5, 1.0)  \n",
       "2       <function equal_odds_tnr at 0x7fae018a2310>      0.064248   [0.2, 10]  \n",
       "3    <function equal_opportunity at 0x7fae018a23a0>      0.102702   [0.2, 10]  \n",
       "4  <function individual_fairness at 0x7fae018a25e0>      0.060000  (0.5, 1.0)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077bf45",
   "metadata": {},
   "source": [
    "\n",
    "For more in-depth analysis, you can run our <\"issue_type\">_sources scan, which will also populate the following: \n",
    "\n",
    "5) feature in relation to which a certain issue type was identified (e.g. drift)\n",
    "\n",
    "6) segment for which a certain issue was detected \n",
    "\n",
    "7) feature and segment combination for which an issue was detected\n",
    "\n",
    "At the moment you also have the option to derive business rules for segments where the issue was identified. This will be covered in notebooks related to the bias scan.\n",
    "\n",
    "\n",
    "Stay tuned for future releases which will incorporate even more details to help you trouble shoot the issue even faster.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a3b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.DataPipeline0634:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0634:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0634:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0634:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0634:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0793:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Start Phase IdentifyPipeline0486\n",
      "INFO:etiq.pipeline.IdentifyPipeline0486:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0486:Starting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raluca/etiq/env/lib/python3.8/site-packages/scipy-1.7.2-py3.8-linux-x86_64.egg/scipy/stats/_entropy.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.IdentifyPipeline0486:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Completed Phase IdentifyPipeline0486\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Start Phase RepairPipeline0934\n",
      "INFO:etiq.pipeline.RepairPipeline0934:Starting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/raluca/etiq/env/lib/python3.8/site-packages/numpy-1.21.4-py3.8-linux-x86_64.egg/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.RepairPipeline0934:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Completed Phase RepairPipeline0934\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Refitting model\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Computed metrics for the repaired dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Compare pipeline predictions\n",
      "INFO:etiq.pipeline.DebiasPipeline0793:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_sources\n",
    "\n",
    "# Run our pipelines\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d13b45c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{10, 7}</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skewed_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skewed_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{0, 1, 5, 6, 9}</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>proxy_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function corrcoef at 0x7fae70303b80&gt;</td>\n",
       "      <td>{race, relationship, educational-num}</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>260</td>\n",
       "      <td>22</td>\n",
       "      <td>(0.0, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function corrcoef at 0x7fae70303b80&gt;</td>\n",
       "      <td>{capital-loss, education, native-country, work...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>260</td>\n",
       "      <td>62</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>low_volume_group</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{4, 7, 9, 10, 12, 14, 19}</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>(1000, inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7fae018a23a0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{0.0, 1.0, 16.0, 17.0, 18.0}</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                          metric  \\\n",
       "0          missing_sample                                            None   \n",
       "1       low_unpriv_sample                                            None   \n",
       "2         low_priv_sample                                            None   \n",
       "3      skewed_priv_sample                                            None   \n",
       "4    skewed_unpriv_sample                                            None   \n",
       "5             proxy_issue                                            None   \n",
       "6       correlation_issue                                            None   \n",
       "7        low_volume_group                                            None   \n",
       "8  limited_features_issue  <function equal_opportunity at 0x7fae018a23a0>   \n",
       "\n",
       "                                 measure  \\\n",
       "0                                   None   \n",
       "1                                   None   \n",
       "2                                   None   \n",
       "3                                   None   \n",
       "4                                   None   \n",
       "5  <function corrcoef at 0x7fae70303b80>   \n",
       "6  <function corrcoef at 0x7fae70303b80>   \n",
       "7                                   None   \n",
       "8                                   None   \n",
       "\n",
       "                                            features  \\\n",
       "0                                                 {}   \n",
       "1                                                 {}   \n",
       "2                                                 {}   \n",
       "3                                                 {}   \n",
       "4                                                 {}   \n",
       "5              {race, relationship, educational-num}   \n",
       "6  {capital-loss, education, native-country, work...   \n",
       "7                                                 {}   \n",
       "8                                                 {}   \n",
       "\n",
       "                                            segments  total_issues_tested  \\\n",
       "0                                            {10, 7}                   20   \n",
       "1  {0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15...                   18   \n",
       "2                                                 {}                   18   \n",
       "3                                                 {}                   13   \n",
       "4                                    {0, 1, 5, 6, 9}                   18   \n",
       "5  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...                  260   \n",
       "6  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...                  260   \n",
       "7                          {4, 7, 9, 10, 12, 14, 19}                   20   \n",
       "8                       {0.0, 1.0, 16.0, 17.0, 18.0}                   20   \n",
       "\n",
       "   issues_found    threshold  \n",
       "0             2   (0.0, 0.0)  \n",
       "1            18   (0.0, 0.8)  \n",
       "2             0   (0.0, 0.8)  \n",
       "3             0   (0.0, 0.2)  \n",
       "4             5   (0.0, 0.2)  \n",
       "5            22   (0.0, 0.5)  \n",
       "6            62   (0.0, 0.2)  \n",
       "7             7  (1000, inf)  \n",
       "8             5   (0.0, 0.2)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b0c4eb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48df62",
   "metadata": {},
   "source": [
    "# Example Scans: Accuracy metrics scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ee59387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.8, 0.1, 0.1],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.7, 1.0]}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq.load_config(\"./config_accuracy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8d626d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a snapshot\n",
    "\n",
    "dataset_loader = etiq.dataset(data_encoded)\n",
    "\n",
    "from etiq.model import DefaultXGBoostClassifier\n",
    "# Load our model\n",
    "model = DefaultXGBoostClassifier()\n",
    "\n",
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Test Snapshot\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "432f8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0661:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0661:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0661:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0661:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0661:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8e071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_below_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7fae018a2040&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy_above_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7fae018a2040&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true_pos_rate_below_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7fae018a20d0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_pos_rate_above_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7fae018a20d0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true_neg_rate_below_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7fae018a2160&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true_neg_rate_above_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7fae018a2160&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                                      metric  \\\n",
       "0       accuracy_below_threshold       <function accuracy at 0x7fae018a2040>   \n",
       "1       accuracy_above_threshold       <function accuracy at 0x7fae018a2040>   \n",
       "2  true_pos_rate_below_threshold  <function true_pos_rate at 0x7fae018a20d0>   \n",
       "3  true_pos_rate_above_threshold  <function true_pos_rate at 0x7fae018a20d0>   \n",
       "4  true_neg_rate_below_threshold  <function true_neg_rate at 0x7fae018a2160>   \n",
       "5  true_neg_rate_above_threshold  <function true_neg_rate at 0x7fae018a2160>   \n",
       "\n",
       "  measure features segments  total_issues_tested  issues_found   threshold  \n",
       "0    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "1    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "2    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "3    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "4    None       {}       {}                    1             0  [0.7, 1.0]  \n",
       "5    None       {}       {}                    1             0  [0.7, 1.0]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d72926b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0363:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0363:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0363:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0363:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0363:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd5980",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
