{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ec1eb3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29557b",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "### Example dataset & model\n",
    "\n",
    "\n",
    "  4. Example model: using Adult dataset, predicts income above/below 50K \n",
    "  \n",
    "### Create a snapshot \n",
    "\n",
    "  5. Log dataset & model \n",
    "  \n",
    "  6. Load a config file\n",
    "  \n",
    "  6. Create a snapshot \n",
    "  \n",
    "  \n",
    "### Scan your snapshot \n",
    "  \n",
    "  7. Run a scan \n",
    "  \n",
    "  8. Retrieve results\n",
    "  \n",
    "  \n",
    "### Example other scans "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d96e3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff524b3",
   "metadata": {},
   "source": [
    "# Quickstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4d5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba75bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid authentication token: 404"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import login as etiq_login\n",
    "etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853c60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Demo Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f999bc",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72d34b",
   "metadata": {},
   "source": [
    "# Example dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e966368",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "First, we'll be encoding the categorical features found in this dataset. \n",
    "\n",
    "Second, we'll log the dataset to Etiq. \n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation. \n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE. \n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example. \n",
    "\n",
    "Remember: This is an example only. The use case for the majority of scans in Etiq is that you log the model to Etiq once you have the sample that you'll be training on. Usually this sample will have numeric features only as otherwise you will not be able to use it in with the majority of supported libraries training methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede7b01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe126d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq.transforms import LabelEncoder\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c6c29",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72e5aa",
   "metadata": {},
   "source": [
    "# Create a snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f86dd5",
   "metadata": {},
   "source": [
    "## Log dataset & model to Etiq \n",
    "\n",
    "For example of how to use Etiq on already-built models check out our other notebooks. \n",
    "\n",
    "In this example we will use a pre-loaded Etiq xgboost wrapper to get you started faster. \n",
    "But in your usual use case you will probably scan a model you already built. \n",
    "\n",
    "If you are planning to use this in production, not just pre-production get in touch with us. We will release integration demos shortly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f5b6d",
   "metadata": {},
   "source": [
    "## Loading the config file \n",
    "\n",
    "The config is where you can set-up the scans you want, and the thresholds outside of which Etiq finds a problem. In the config you input relevant parameters (e.g. for bias/fairness scans you'll have to tell Etiq which feature is a demographic and which value represents a protected group). \n",
    "For more details on the config just check the documentation. You can upload these config files from wherever you want. We provide examples in the Demo repo with each notebook.   \n",
    "\n",
    "The config gets stored in the database so you can have a log and version control. You will need to load the config before you log the dataset and the model as Etiq will check if it has enough information to process them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea8f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq.model import DefaultXGBoostClassifier\n",
    "\n",
    "with etiq.etiq_config(\"./config_bias.json\"):\n",
    "    \n",
    "    #load your dataset\n",
    "    dataset = etiq.BiasDatasetBuilder.dataset(data_encoded)\n",
    "    \n",
    "    #load our model\n",
    "    model = DefaultXGBoostClassifier()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da3126",
   "metadata": {},
   "source": [
    "## Creating a Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c075662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Created histogram summary of data (15 fields)\n"
     ]
    }
   ],
   "source": [
    "with etiq.etiq_config(\"./config_bias.json\"):\n",
    "    #create a snapshot\n",
    "    snapshot = project.snapshots.create(name=\"Test Snapshot\", \n",
    "                                        dataset=dataset, \n",
    "                                        model=model, \n",
    "                                        bias_params=etiq.BiasDatasetBuilder.bias_params()\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97f69a",
   "metadata": {},
   "source": [
    "## Run Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c179fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0901:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0901:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Issue Aggregate = {'demographic_parity_above_threshold': IssueAggregate(name='demographic_parity_above_threshold', metric=<compiled_function demographic_parity at 0x7fcddda808b0>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'equal_odds_tpr_above_threshold': IssueAggregate(name='equal_odds_tpr_above_threshold', metric=<compiled_function equal_odds_tpr at 0x7fcddda809a0>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'equal_odds_tnr_above_threshold': IssueAggregate(name='equal_odds_tnr_above_threshold', metric=<compiled_function equal_odds_tnr at 0x7fcddda80a90>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'equal_opportunity_above_threshold': IssueAggregate(name='equal_opportunity_above_threshold', metric=<compiled_function equal_opportunity at 0x7fcddda80b80>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'individual_fairness_above_threshold': IssueAggregate(name='individual_fairness_above_threshold', metric=<compiled_function individual_fairness at 0x7fcdddaab040>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0))}\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Threshold (0.18633280701593335, 10)\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Threshold (0.10270214943705225, 1.0)\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Threshold (0.06424802617523284, 10)\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Threshold (0.10270214943705225, 10)\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Threshold (0.05999999999999994, 1.0)\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0901:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "with etiq.etiq_config(\"./config_bias.json\"):\n",
    "    #scan_bias_metrics\n",
    "    (segments, issues, issue_summary) = snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bb4c4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719e37e",
   "metadata": {},
   "source": [
    "## Bias Metrics & Bias Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea0744",
   "metadata": {},
   "source": [
    "\n",
    "Scan results are fairly self-explanatory. To help with root cause analysis we give information on:\n",
    "\n",
    "1) each issue tested as part of the scan \n",
    "\n",
    "2) if the issue was found\n",
    "\n",
    "3) what is the metric the test was based on and what is the value of the metric \n",
    "\n",
    "4) what are the thresholds outside which an issue is detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "830e8675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077bf45",
   "metadata": {},
   "source": [
    "\n",
    "For more in-depth analysis, you can run our <\"issue_type\">_sources scan, which will also populate the following: \n",
    "\n",
    "5) feature in relation to which a certain issue type was identified (e.g. drift)\n",
    "\n",
    "6) segment for which a certain issue was detected \n",
    "\n",
    "7) feature and segment combination for which an issue was detected\n",
    "\n",
    "At the moment you also have the option to derive business rules for segments where the issue was identified. This will be covered in notebooks related to the bias scan.\n",
    "\n",
    "\n",
    "Stay tuned for future releases which will incorporate even more details to help you trouble shoot the issue even faster.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a3b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.DataPipeline0758:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0758:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0758:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0758:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0758:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0185:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0185:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0185:Start Phase IdentifyPipeline0254\n",
      "INFO:etiq.pipeline.IdentifyPipeline0254:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0254:Starting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/scipy/stats/_entropy.py:77: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.pipeline.IdentifyPipeline0254:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0185:Completed Phase IdentifyPipeline0254\n",
      "INFO:etiq.pipeline.DebiasPipeline0185:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0185:Completed pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/School/opt/anaconda3/envs/python/lib/python3.9/site-packages/etiq/pipelines/steps.py:1753: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_sources\n",
    "\n",
    "# Run our pipelines\n",
    "(segments_sources, issues_sources, issue_summary_sources) = snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13b45c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{10, 7}</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skewed_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skewed_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{0, 1, 5, 6, 9}</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low_volume_group</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{4, 7, 9, 10, 12, 14, 19}</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>(1000, inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>&lt;compiled_function equal_opportunity at 0x7fcd...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{16.0, 19.0}</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proxy_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;compiled_function pointbiserial at 0x7fcddd59...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proxy_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;compiled_function cramersv at 0x7fcddd598640&gt;</td>\n",
       "      <td>{education, race, marital-status, relationship...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;compiled_function pointbiserial at 0x7fcddd59...</td>\n",
       "      <td>{capital-loss, fnlwgt, age, capital-gain, hour...</td>\n",
       "      <td>{0, 4, 7, 10, 12, 14}</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;compiled_function cramersv at 0x7fcddd598640&gt;</td>\n",
       "      <td>{education, native-country, workclass, race, m...</td>\n",
       "      <td>{4, 7, 10, 12, 14}</td>\n",
       "      <td>160</td>\n",
       "      <td>29</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                             metric  \\\n",
       "0           missing_sample                                               None   \n",
       "1        low_unpriv_sample                                               None   \n",
       "2          low_priv_sample                                               None   \n",
       "3       skewed_priv_sample                                               None   \n",
       "4     skewed_unpriv_sample                                               None   \n",
       "5         low_volume_group                                               None   \n",
       "6   limited_features_issue  <compiled_function equal_opportunity at 0x7fcd...   \n",
       "7              proxy_issue                                               None   \n",
       "8              proxy_issue                                               None   \n",
       "9        correlation_issue                                               None   \n",
       "10       correlation_issue                                               None   \n",
       "\n",
       "                                              measure  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7   <compiled_function pointbiserial at 0x7fcddd59...   \n",
       "8      <compiled_function cramersv at 0x7fcddd598640>   \n",
       "9   <compiled_function pointbiserial at 0x7fcddd59...   \n",
       "10     <compiled_function cramersv at 0x7fcddd598640>   \n",
       "\n",
       "                                             features  \\\n",
       "0                                                  {}   \n",
       "1                                                  {}   \n",
       "2                                                  {}   \n",
       "3                                                  {}   \n",
       "4                                                  {}   \n",
       "5                                                  {}   \n",
       "6                                                  {}   \n",
       "7                                                  {}   \n",
       "8   {education, race, marital-status, relationship...   \n",
       "9   {capital-loss, fnlwgt, age, capital-gain, hour...   \n",
       "10  {education, native-country, workclass, race, m...   \n",
       "\n",
       "                                             segments  total_issues_tested  \\\n",
       "0                                             {10, 7}                   20   \n",
       "1                                                  {}                   18   \n",
       "2                                                  {}                   18   \n",
       "3                                                  {}                   13   \n",
       "4                                     {0, 1, 5, 6, 9}                   18   \n",
       "5                           {4, 7, 9, 10, 12, 14, 19}                   20   \n",
       "6                                        {16.0, 19.0}                   20   \n",
       "7                                                  {}                  100   \n",
       "8   {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...                  160   \n",
       "9                               {0, 4, 7, 10, 12, 14}                  100   \n",
       "10                                 {4, 7, 10, 12, 14}                  160   \n",
       "\n",
       "    issues_found    threshold  \n",
       "0              2   (0.0, 0.0)  \n",
       "1              0   (0.0, 0.8)  \n",
       "2              0   (0.0, 0.8)  \n",
       "3              0   (0.0, 0.2)  \n",
       "4              5   (0.0, 0.2)  \n",
       "5              7  (1000, inf)  \n",
       "6              2   (0.0, 0.2)  \n",
       "7              0   (0.0, 1.0)  \n",
       "8             30   (0.0, 1.0)  \n",
       "9             21   (0.0, 1.0)  \n",
       "10            29   (0.0, 1.0)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b0c4eb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48df62",
   "metadata": {},
   "source": [
    "# Example Scans: Accuracy metrics scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d40e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Histogram summary already created for this data.\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Computed acurracy metrics for the dataset {'accuracy': 0.87, 'true_pos_rate': 0.6690328305235137, 'true_neg_rate': 0.9302820649281532}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Issue Aggregate = {'accuracy_below_threshold': IssueAggregate(name='accuracy_below_threshold', metric=<compiled_function accuracy at 0x7fcddda805e0>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_pos_rate_below_threshold': IssueAggregate(name='true_pos_rate_below_threshold', metric=<compiled_function true_pos_rate at 0x7fcddda806d0>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_neg_rate_below_threshold': IssueAggregate(name='true_neg_rate_below_threshold', metric=<compiled_function true_neg_rate at 0x7fcddda807c0>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0))}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Threshold (0.8, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Threshold (0.7, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0882:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "from etiq.model import DefaultXGBoostClassifier\n",
    "\n",
    "with etiq.etiq_config(\"./config_accuracy.json\"):\n",
    "    \n",
    "    #load your dataset\n",
    "    dataset = etiq.BiasDatasetBuilder.dataset(data_encoded)\n",
    "    \n",
    "    #load our model\n",
    "    model = DefaultXGBoostClassifier()\n",
    "    \n",
    "    #create a snapshot\n",
    "    snapshot = project.snapshots.create(name=\"Test Snapshot\", \n",
    "                                        dataset=dataset, \n",
    "                                        model=model, \n",
    "                                        bias_params=etiq.BiasDatasetBuilder.bias_params()\n",
    "                                       )\n",
    "    #scan_accuracy_metrics\n",
    "    (segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_below_threshold</td>\n",
       "      <td>&lt;compiled_function accuracy at 0x7fcddda805e0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_pos_rate_below_threshold</td>\n",
       "      <td>&lt;compiled_function true_pos_rate at 0x7fcddda8...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true_neg_rate_below_threshold</td>\n",
       "      <td>&lt;compiled_function true_neg_rate at 0x7fcddda8...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0       accuracy_below_threshold   \n",
       "1  true_pos_rate_below_threshold   \n",
       "2  true_neg_rate_below_threshold   \n",
       "\n",
       "                                              metric measure features  \\\n",
       "0     <compiled_function accuracy at 0x7fcddda805e0>    None       {}   \n",
       "1  <compiled_function true_pos_rate at 0x7fcddda8...    None       {}   \n",
       "2  <compiled_function true_neg_rate at 0x7fcddda8...    None       {}   \n",
       "\n",
       "  segments  total_issues_tested  issues_found   threshold  \n",
       "0       {}                    1             0  [0.7, 1.0]  \n",
       "1       {}                    1             0  [0.7, 1.0]  \n",
       "2       {}                    1             0  [0.7, 1.0]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd5980",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
