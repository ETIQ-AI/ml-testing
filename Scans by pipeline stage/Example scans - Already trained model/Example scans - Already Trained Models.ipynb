{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcdee43e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1789c4db",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "### Example dataset & model\n",
    "\n",
    "\n",
    "  4. Example model: using Adult dataset, predicts income above/below 50K \n",
    "  \n",
    "### Create a snapshot \n",
    "\n",
    "  5. Log dataset & model \n",
    "  \n",
    "  6. Load a config file\n",
    "  \n",
    "  6. Create a snapshot \n",
    "  \n",
    "  \n",
    "### Scan your snapshot \n",
    "  \n",
    "  7. Run a scan \n",
    "  \n",
    "  8. Retrieve results\n",
    "  \n",
    "  \n",
    "### Example other scans "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62b6cf5",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ff524b3",
   "metadata": {},
   "source": [
    "# Quickstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4d5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.AI toolkit!\n",
      "\n",
      "This is a trial version, you have 14 days remaining in your trial period.\n",
      "Please consider purchasing the full version to continue enjoying all the features of our library.\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "Help improve our product: Call `etiq.enable_telemetry()` to provide\n",
      "anonymous library usage statistics.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba75bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connection successful. Projects and pipelines will be displayed in the dashboard. ðŸ˜€'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import login as etiq_login\n",
    "etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ec9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ETIQ:Project [fkjdT9NzKEKqDu2yX5uzC9] \"Demo Already Trained\">]\n"
     ]
    }
   ],
   "source": [
    "# Can enumerate all available projects\n",
    "all_projects = etiq.projects.get_all_projects()\n",
    "print(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Demo Already Trained\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "116f14b3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c72d34b",
   "metadata": {},
   "source": [
    "# Example dataset and model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e966368",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "1. Import the dataset\n",
    "\n",
    "2. Pre-process the dataset \n",
    "\n",
    "3. Build the model \n",
    "\n",
    "4. Log the dataset and already built model to Etiq\n",
    "\n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation. \n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE. \n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example. \n",
    "\n",
    "Remember: This is an example only. The use case for the majority of scans in Etiq is that you log the model to Etiq once you have the sample that you'll be training on. Usually this sample will have numeric features only as otherwise you will not be able to use it in with the majority of supported libraries training methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe126d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdataset.csv\")\n",
    "data.replace(\"?\", np.nan)\n",
    "data.dropna(inplace=True)\n",
    "data.head()\n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = [\"age\", \"educational-num\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "cat_vars = sorted(list(set(data.columns.values) - set(cont_vars)))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2a5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training/testing/validation datasets\n",
    "\n",
    "# separate into train/validate/test dataset of sizes 80%/10%/10% as percetages of the initial data\n",
    "data_remaining, test = train_test_split(data_encoded, test_size=0.1)\n",
    "train, valid = train_test_split(data_remaining, test_size=0.1112)\n",
    "\n",
    "# because we don't want to train on protected attributes or labels to be predicted, \n",
    "# let's remove these columns from the training dataset\n",
    "protected_train = train['gender'].copy() # gender is a protected attribute\n",
    "y_train = train['income'].copy() # labels we're going to train the model to predict\n",
    "x_train = train.drop(columns=['gender','income'])\n",
    "protected_valid = valid['gender'].copy() \n",
    "y_valid = valid['income'].copy() \n",
    "x_valid = valid.drop(columns=['gender','income'])\n",
    "protected_test = test['gender'].copy() \n",
    "y_test = test['income'].copy()\n",
    "x_test = test.drop(columns=['gender','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model to predict 'income'\n",
    "\n",
    "standard_model = XGBClassifier(eval_metric='logloss', random_state=4)    \n",
    "model_fit = standard_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92eee327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the training dataset : 90.1 %\n",
      "Model accuracy on the validation dataset : 87.69 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = standard_model.predict(x_train)\n",
    "y_valid_pred = standard_model.predict(x_valid)\n",
    "print('Model accuracy on the training dataset :', \n",
    "      round(100 * accuracy_score(y_train, y_train_pred),2),'%') # round the score to 2 digits  \n",
    "\n",
    "print('Model accuracy on the validation dataset :', \n",
    "      round(100 * accuracy_score(y_valid, y_valid_pred),2),'%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ae7ea2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf961655",
   "metadata": {},
   "source": [
    "# Log dataset & model snapshot to Etiq \n",
    "\n",
    "This is an example of how you log the already trained model to Etiq.\n",
    "\n",
    "When you log the dataset make sure you log a new sample or a test sample, not the sample you trained you model on. \n",
    "\n",
    "When you log the config, make sure the % for train and valid splits are 0. \n",
    "\n",
    "If you are planning to use this in production, not just pre-production get in touch with us. We will release integration demos shortly.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74e131e7",
   "metadata": {},
   "source": [
    "## Loading the config file \n",
    "\n",
    "The config is where you can set-up the scans you want, and the thresholds outside of which Etiq finds a problem. In the config you input relevant parameters (e.g. for bias/fairness scans you'll have to tell Etiq which feature is a demographic and which value represents a protected group). \n",
    "For more details on the config just check the documentation. You can upload these config files from wherever you want. We provide examples in the Demo repo with each notebook.   \n",
    "\n",
    "The config gets stored in the database so you can have a log and version control. \n",
    "\n",
    "When you log the config for an already trained model, please log \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ab3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.0, 1.0, 0.0],\n",
       "  'remove_protected_from_features': True},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.8],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_leakage': {'leakage_threshold': 0.85}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "etiq.load_config(\"./config_already_trained.json\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c4216ef",
   "metadata": {},
   "source": [
    "## Log the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "\n",
    "#log your dataset\n",
    "\n",
    "dataset = etiq.BiasDatasetBuilder.dataset(test)\n",
    "bias_params = etiq.BiasDatasetBuilder.bias_params()\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f2ebdfc",
   "metadata": {},
   "source": [
    "## Creating a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5277cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Created histogram summary of data (14 fields)\n"
     ]
    }
   ],
   "source": [
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Test Snapshot\",\n",
    "                                    dataset=dataset,\n",
    "                                    model=model,\n",
    "                                    bias_params=bias_params)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6b43d3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f107538d",
   "metadata": {},
   "source": [
    "# Run scans\n",
    "\n",
    "You can run multiple scans for snapshot. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8719e37e",
   "metadata": {},
   "source": [
    "## Bias Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3545fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0374:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0374:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "Exclude Features = None\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Threshold issues ['demographic_parity_above_threshold']\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Min threshold = 0.0, Max threshold = 0.2\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Threshold issues ['equal_odds_tpr_above_threshold']\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Min threshold = 0.0, Max threshold = 0.2\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Threshold issues ['equal_odds_tnr_above_threshold']\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Min threshold = 0.0, Max threshold = 0.2\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Threshold issues ['equal_opportunity_above_threshold']\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Min threshold = 0.0, Max threshold = 0.2\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Threshold issues ['individual_fairness_above_threshold']\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Min threshold = 0.0, Max threshold = 0.8\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0374:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_metrics\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830e8675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13b45c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demographic_parity_above_threshold</td>\n",
       "      <td>&lt;function demographic_parity at 0x7f192e1e4d30&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equal_odds_tpr_above_threshold</td>\n",
       "      <td>&lt;function equal_odds_tpr at 0x7f192e1e4e50&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equal_odds_tnr_above_threshold</td>\n",
       "      <td>&lt;function equal_odds_tnr at 0x7f192e1e4f70&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equal_opportunity_above_threshold</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f192e1ee0d0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>individual_fairness_above_threshold</td>\n",
       "      <td>&lt;function individual_fairness at 0x7f192e1ee3a0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0   demographic_parity_above_threshold   \n",
       "1       equal_odds_tpr_above_threshold   \n",
       "2       equal_odds_tnr_above_threshold   \n",
       "3    equal_opportunity_above_threshold   \n",
       "4  individual_fairness_above_threshold   \n",
       "\n",
       "                                             metric measure features segments  \\\n",
       "0   <function demographic_parity at 0x7f192e1e4d30>    None       {}       {}   \n",
       "1       <function equal_odds_tpr at 0x7f192e1e4e50>    None       {}       {}   \n",
       "2       <function equal_odds_tnr at 0x7f192e1e4f70>    None       {}       {}   \n",
       "3    <function equal_opportunity at 0x7f192e1ee0d0>    None       {}       {}   \n",
       "4  <function individual_fairness at 0x7f192e1ee3a0>    None       {}       {}   \n",
       "\n",
       "   total_issues_tested  issues_found   threshold  \n",
       "0                    1             0  [0.0, 0.2]  \n",
       "1                    1             0  [0.0, 0.2]  \n",
       "2                    1             0  [0.0, 0.2]  \n",
       "3                    1             0  [0.0, 0.2]  \n",
       "4                    1             0  [0.0, 0.8]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c48df62",
   "metadata": {},
   "source": [
    "## Accuracy metrics scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432f8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Computed acurracy metrics for the dataset {'accuracy': 0.87, 'true_pos_rate': 0.6434108527131783, 'true_neg_rate': 0.9374328678839957}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Threshold issues ['accuracy_below_threshold']\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Min threshold = 0.8, Max threshold = 1.0\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Threshold issues ['true_pos_rate_below_threshold']\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Min threshold = 0.6, Max threshold = 1.0\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Threshold issues ['true_neg_rate_below_threshold']\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Min threshold = 0.6, Max threshold = 1.0\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0099:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_below_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7f192e1e49d0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_pos_rate_below_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7f192e1e4af0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true_neg_rate_below_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7f192e1e4c10&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                                      metric  \\\n",
       "0       accuracy_below_threshold       <function accuracy at 0x7f192e1e49d0>   \n",
       "1  true_pos_rate_below_threshold  <function true_pos_rate at 0x7f192e1e4af0>   \n",
       "2  true_neg_rate_below_threshold  <function true_neg_rate at 0x7f192e1e4c10>   \n",
       "\n",
       "  measure features segments  total_issues_tested  issues_found   threshold  \n",
       "0    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "1    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "2    None       {}       {}                    1             0  [0.6, 1.0]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e2b27bd",
   "metadata": {},
   "source": [
    "# Bias Sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2beaf06",
   "metadata": {},
   "source": [
    "Even if your training and test samples are very similar, the bias sources are related to properties of the training dataset, not the test dataset. \n",
    "\n",
    "To run bias sources even if you have an already trained model please use the TRAINING dataset instead.\n",
    "\n",
    "You will need to change the train_test_valid in your config & then re-log your snapshots. You will still have the same model architecture from your already trained model, but if the scans show issues we recommend you clean your data and retrain the model. \n",
    "\n",
    "To be able to use bias sources you will have to log which features are categorical and which are numeric. \n",
    "\n",
    "You can do this in the config or in the notebook if easier. Commented out example shows you how to you do it in your notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d867c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiq Configuration:\n",
      "{\n",
      "    \"dataset\": {\n",
      "        \"label\": \"income\",\n",
      "        \"bias_params\": {\n",
      "            \"protected\": \"gender\",\n",
      "            \"privileged\": 1,\n",
      "            \"unprivileged\": 0,\n",
      "            \"positive_outcome_label\": 1,\n",
      "            \"negative_outcome_label\": 0\n",
      "        },\n",
      "        \"train_valid_test_splits\": [\n",
      "            1.0,\n",
      "            0.01,\n",
      "            0.0\n",
      "        ],\n",
      "        \"remove_protected_from_features\": true,\n",
      "        \"cat_col\": [\n",
      "            \"workclass\",\n",
      "            \"relationship\",\n",
      "            \"occupation\",\n",
      "            \"gender\",\n",
      "            \"race\",\n",
      "            \"native-country\",\n",
      "            \"marital-status\",\n",
      "            \"income\",\n",
      "            \"education\"\n",
      "        ],\n",
      "        \"cont_col\": [\n",
      "            \"age\",\n",
      "            \"educational-num\",\n",
      "            \"fnlwgt\",\n",
      "            \"capital-gain\",\n",
      "            \"capital-loss\",\n",
      "            \"hours-per-week\"\n",
      "        ]\n",
      "    },\n",
      "    \"scan_bias_sources\": {\n",
      "        \"auto\": true\n",
      "    },\n",
      "    \"scan_accuracy_metrics\": {\n",
      "        \"thresholds\": {\n",
      "            \"accuracy\": [\n",
      "                0.8,\n",
      "                1.0\n",
      "            ],\n",
      "            \"true_pos_rate\": [\n",
      "                0.6,\n",
      "                1.0\n",
      "            ],\n",
      "            \"true_neg_rate\": [\n",
      "                0.6,\n",
      "                1.0\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"scan_bias_metrics\": {\n",
      "        \"thresholds\": {\n",
      "            \"equal_opportunity\": [\n",
      "                0.0,\n",
      "                0.2\n",
      "            ],\n",
      "            \"demographic_parity\": [\n",
      "                0.0,\n",
      "                0.2\n",
      "            ],\n",
      "            \"equal_odds_tnr\": [\n",
      "                0.0,\n",
      "                0.2\n",
      "            ],\n",
      "            \"individual_fairness\": [\n",
      "                0.0,\n",
      "                0.8\n",
      "            ],\n",
      "            \"equal_odds_tpr\": [\n",
      "                0.0,\n",
      "                0.2\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"scan_leakage\": {\n",
      "        \"leakage_threshold\": 0.85\n",
      "    }\n",
      "}\n",
      "INFO:etiq.charting:Created histogram summary of data (14 fields)\n",
      "WARNING:etiq.pipeline.DataPipeline0349:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0349:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0349:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0349:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0349:Completed pipeline\n",
      "Running auto bias sources pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0371:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0371:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0371:Start Phase IdentifyPipeline0194\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking proxy for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking correlation for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Checking Skew\n",
      "INFO:etiq.pipeline.IdentifyPipeline0194:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0371:Completed Phase IdentifyPipeline0194\n",
      "INFO:etiq.pipeline.DebiasPipeline0371:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0371:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "from etiq import Model\n",
    "import json\n",
    "# \n",
    "with etiq.etiq_config(\"./config_already_trained_bias_sources.json\"):\n",
    "    # Print out the config\n",
    "    print(f\"Etiq Configuration:\\n{json.dumps(etiq.get_config(), indent=4)}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = etiq.BiasDatasetBuilder.datasets(training_features=train,\n",
    "                                               validation_features=test)\n",
    "    # Load the bias parameters\n",
    "    bias_params = etiq.BiasDatasetBuilder.bias_params()\n",
    "\n",
    "    # Create your already trained model and log it.\n",
    "    model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "    # Create the \"Bias Sources Snapshot\"\n",
    "    snapshot = project.snapshots.create(name=\"Bias Sources (Testing) Snapshot\",\n",
    "                                        dataset=dataset,\n",
    "                                        model=model,\n",
    "                                        bias_params=bias_params)\n",
    "    # Scan for sources of bias in the training data\n",
    "    (bias_sources_segments_training,\n",
    "     bias_sources_issues_training,\n",
    "     bias_sources_issue_summary_training) = snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a43550d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{98}</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{3, 17, 18, 19, 20, 21, 30, 31, 32, 34, 46, 49...</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1, 2, 67, 33, 5, 37, 38, 29}</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>(0.0, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skewed_priv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skewed_unpriv_sample</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{96, 97, 40, 41, 42, 43, 13, 48, 17, 51, 83, 5...</td>\n",
       "      <td>98</td>\n",
       "      <td>17</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low_volume_group</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>(781.36, inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limited_features_issue</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f192e1ee0d0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{4.0, 71.0, 42.0, 11.0, 12.0, 56.0, 95.0}</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>(0.0, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proxy_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function pointbiserial at 0x7f192e1deca0&gt;</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proxy_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function cramersv at 0x7f192e1deb80&gt;</td>\n",
       "      <td>{relationship, occupation, marital-status}</td>\n",
       "      <td>{3, 6, 8, 9, 13, 18, 19, 20, 23, 24, 26, 30, 3...</td>\n",
       "      <td>693</td>\n",
       "      <td>82</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function pointbiserial at 0x7f192e1deca0&gt;</td>\n",
       "      <td>{capital-gain, capital-loss, fnlwgt, age, educ...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>594</td>\n",
       "      <td>144</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>correlation_issue</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function cramersv at 0x7f192e1deb80&gt;</td>\n",
       "      <td>{occupation, native-country, marital-status, e...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>693</td>\n",
       "      <td>284</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                          metric  \\\n",
       "0           missing_sample                                            None   \n",
       "1        low_unpriv_sample                                            None   \n",
       "2          low_priv_sample                                            None   \n",
       "3       skewed_priv_sample                                            None   \n",
       "4     skewed_unpriv_sample                                            None   \n",
       "5         low_volume_group                                            None   \n",
       "6   limited_features_issue  <function equal_opportunity at 0x7f192e1ee0d0>   \n",
       "7              proxy_issue                                            None   \n",
       "8              proxy_issue                                            None   \n",
       "9        correlation_issue                                            None   \n",
       "10       correlation_issue                                            None   \n",
       "\n",
       "                                       measure  \\\n",
       "0                                         None   \n",
       "1                                         None   \n",
       "2                                         None   \n",
       "3                                         None   \n",
       "4                                         None   \n",
       "5                                         None   \n",
       "6                                         None   \n",
       "7   <function pointbiserial at 0x7f192e1deca0>   \n",
       "8        <function cramersv at 0x7f192e1deb80>   \n",
       "9   <function pointbiserial at 0x7f192e1deca0>   \n",
       "10       <function cramersv at 0x7f192e1deb80>   \n",
       "\n",
       "                                             features  \\\n",
       "0                                                  {}   \n",
       "1                                                  {}   \n",
       "2                                                  {}   \n",
       "3                                                  {}   \n",
       "4                                                  {}   \n",
       "5                                                  {}   \n",
       "6                                                  {}   \n",
       "7                                                  {}   \n",
       "8          {relationship, occupation, marital-status}   \n",
       "9   {capital-gain, capital-loss, fnlwgt, age, educ...   \n",
       "10  {occupation, native-country, marital-status, e...   \n",
       "\n",
       "                                             segments  total_issues_tested  \\\n",
       "0                                                {98}                   99   \n",
       "1   {3, 17, 18, 19, 20, 21, 30, 31, 32, 34, 46, 49...                   98   \n",
       "2                       {1, 2, 67, 33, 5, 37, 38, 29}                   98   \n",
       "3                                                  {}                   81   \n",
       "4   {96, 97, 40, 41, 42, 43, 13, 48, 17, 51, 83, 5...                   98   \n",
       "5                                                  {}                   99   \n",
       "6           {4.0, 71.0, 42.0, 11.0, 12.0, 56.0, 95.0}                   99   \n",
       "7                                                  {}                  594   \n",
       "8   {3, 6, 8, 9, 13, 18, 19, 20, 23, 24, 26, 30, 3...                  693   \n",
       "9   {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...                  594   \n",
       "10  {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...                  693   \n",
       "\n",
       "    issues_found      threshold  \n",
       "0              1     (0.0, 0.0)  \n",
       "1             20     (0.0, 0.8)  \n",
       "2              8     (0.0, 0.8)  \n",
       "3              0     (0.0, 0.2)  \n",
       "4             17     (0.0, 0.2)  \n",
       "5              0  (781.36, inf)  \n",
       "6              7     (0.0, 0.2)  \n",
       "7              0     (0.0, 1.0)  \n",
       "8             82     (0.0, 1.0)  \n",
       "9            144     (0.0, 1.0)  \n",
       "10           284     (0.0, 1.0)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_sources_issue_summary_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daf9a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiq Configuration:\n",
      "{'dataset': {'label': 'income', 'bias_params': {'protected': 'gender', 'privileged': 1, 'unprivileged': 0, 'positive_outcome_label': 1, 'negative_outcome_label': 0}, 'train_valid_test_splits': [1.0, 0.01, 0.0], 'remove_protected_from_features': True}, 'scan_bias_sources': {'auto': True}, 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0], 'true_pos_rate': [0.6, 1.0], 'true_neg_rate': [0.6, 1.0]}}, 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2], 'demographic_parity': [0.0, 0.2], 'equal_odds_tnr': [0.0, 0.2], 'individual_fairness': [0.0, 0.8], 'equal_odds_tpr': [0.0, 0.2]}}, 'scan_leakage': {'leakage_threshold': 0.85}}\n",
      "INFO:etiq.charting:Created histogram summary of data (14 fields)\n",
      "WARNING:etiq.pipeline.DataPipeline0020:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0020:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0020:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0020:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0020:Completed pipeline\n",
      "Running auto bias sources pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0023:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0023:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0023:Start Phase IdentifyPipeline0937\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using pointbiserial\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking proxy for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated proxy using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking correlation for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Calculated correlation using cramersv\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Checking Skew\n",
      "INFO:etiq.pipeline.IdentifyPipeline0937:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0023:Completed Phase IdentifyPipeline0937\n",
      "INFO:etiq.pipeline.DebiasPipeline0023:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0023:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with etiq.etiq_config(\"./config_already_trained_bias_sources2.json\"):\n",
    "    # Print out the config\n",
    "    print(f\"Etiq Configuration:\\n{etiq.get_config()}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = etiq.BiasDatasetBuilder.datasets(training_features=test,\n",
    "                                               validation_features=valid)\n",
    "    # Load the bias parameters\n",
    "    bias_params = etiq.BiasDatasetBuilder.bias_params()\n",
    "\n",
    "    # Create your already trained model and log it.\n",
    "    model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "    # Create the \"Bias Sources Snapshot\"\n",
    "    snapshot = project.snapshots.create(name=\"Bias Sources (Training) Snapshot\",\n",
    "                                        dataset=dataset,\n",
    "                                        model=model,\n",
    "                                        bias_params=bias_params)\n",
    "    # Scan for sources of bias in the training data\n",
    "    (bias_sources_segments_testing,\n",
    "     bias_sources_issues_testing,\n",
    "     bias_sources_issue_summary_testing) = snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92ef710b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>business_rule</th>\n",
       "      <th>mask</th>\n",
       "      <th>tags</th>\n",
       "      <th>is_global</th>\n",
       "      <th>number_of_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>`relationship` == 3 and `fnlwgt` &lt;= 308205.865...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>`relationship` == 3 and `fnlwgt` &gt; 308205.8652...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>`relationship` == 1 and `fnlwgt` &lt;= 51917.3926...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>`relationship` == 1 and `fnlwgt` &gt; 51917.39266...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>`relationship` == 1 and `fnlwgt` &gt; 51917.39266...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>`relationship` == 1 and `race` == 4 and `fnlwg...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>`relationship` == 1 and `race` == 2</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>`relationship` == 4 and `education` &gt; 8.0</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>`relationship` == 0</td>\n",
       "      <td>[False, False, False, True, False, True, False...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>`relationship` == 5</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                      business_rule  \\\n",
       "0       0  `relationship` == 3 and `fnlwgt` <= 308205.865...   \n",
       "1       1  `relationship` == 3 and `fnlwgt` > 308205.8652...   \n",
       "2       2  `relationship` == 1 and `fnlwgt` <= 51917.3926...   \n",
       "3       3  `relationship` == 1 and `fnlwgt` > 51917.39266...   \n",
       "4       4  `relationship` == 1 and `fnlwgt` > 51917.39266...   \n",
       "..    ...                                                ...   \n",
       "110   110  `relationship` == 1 and `race` == 4 and `fnlwg...   \n",
       "111   111                `relationship` == 1 and `race` == 2   \n",
       "112   112          `relationship` == 4 and `education` > 8.0   \n",
       "113   113                                `relationship` == 0   \n",
       "114   114                                `relationship` == 5   \n",
       "\n",
       "                                                  mask tags  is_global  \\\n",
       "0    [False, False, False, False, False, False, Fal...   {}      False   \n",
       "1    [False, False, False, False, False, False, Fal...   {}      False   \n",
       "2    [False, False, False, False, False, False, Fal...   {}      False   \n",
       "3    [False, False, False, False, False, False, Tru...   {}      False   \n",
       "4    [False, False, False, False, False, False, Fal...   {}      False   \n",
       "..                                                 ...  ...        ...   \n",
       "110  [False, False, False, False, False, False, Fal...   {}      False   \n",
       "111  [False, False, False, False, False, False, Fal...   {}      False   \n",
       "112  [False, False, False, False, False, False, Fal...   {}      False   \n",
       "113  [False, False, False, True, False, True, False...   {}      False   \n",
       "114  [False, False, False, False, True, False, Fals...   {}      False   \n",
       "\n",
       "     number_of_samples  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "..                 ...  \n",
       "110                  0  \n",
       "111                  0  \n",
       "112                  0  \n",
       "113                  0  \n",
       "114                  0  \n",
       "\n",
       "[115 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_sources_segments_testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
