{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdee43e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789c4db",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "### Example dataset & model\n",
    "\n",
    "\n",
    "  4. Example model: using Adult dataset, predicts income above/below 50K \n",
    "  \n",
    "### Create a snapshot \n",
    "\n",
    "  5. Log dataset & model \n",
    "  \n",
    "  6. Load a config file\n",
    "  \n",
    "  6. Create a snapshot \n",
    "  \n",
    "  \n",
    "### Scan your snapshot \n",
    "  \n",
    "  7. Run a scan \n",
    "  \n",
    "  8. Retrieve results\n",
    "  \n",
    "  \n",
    "### Example other scans "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b6cf5",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff524b3",
   "metadata": {},
   "source": [
    "# Quickstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4d5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba75bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dashboard supplied updated license information)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Connection successful. Projects and pipelines will be displayed in the dashboard. ðŸ˜€"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import login as etiq_login\n",
    "etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ec9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ETIQ:Project [1] \"Demo Project\">, <ETIQ:Project [2] \"Test Already Trained\">]\n"
     ]
    }
   ],
   "source": [
    "# Can enumerate all available projects\n",
    "all_projects = etiq.projects.get_all_projects()\n",
    "print(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Demo Already Trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f14b3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72d34b",
   "metadata": {},
   "source": [
    "# Example dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e966368",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "1. Import the dataset\n",
    "\n",
    "2. Pre-process the dataset \n",
    "\n",
    "3. Build the model \n",
    "\n",
    "4. Log the dataset and already built model to Etiq\n",
    "\n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation. \n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE. \n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example. \n",
    "\n",
    "Remember: This is an example only. The use case for the majority of scans in Etiq is that you log the model to Etiq once you have the sample that you'll be training on. Usually this sample will have numeric features only as otherwise you will not be able to use it in with the majority of supported libraries training methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe126d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2a5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training/testing/validation datasets\n",
    "\n",
    "# separate into train/validate/test dataset of sizes 80%/10%/10% as percetages of the initial data\n",
    "data_remaining, test = train_test_split(data_encoded, test_size=0.1)\n",
    "train, valid = train_test_split(data_remaining, test_size=0.1112)\n",
    "\n",
    "# because we don't want to train on protected attributes or labels to be predicted, \n",
    "# let's remove these columns from the training dataset\n",
    "protected_train = train['gender'].copy() # gender is a protected attribute\n",
    "y_train = train['income'].copy() # labels we're going to train the model to predict\n",
    "x_train = train.drop(columns=['gender','income'])\n",
    "protected_valid = valid['gender'].copy() \n",
    "y_valid = valid['income'].copy() \n",
    "x_valid = valid.drop(columns=['gender','income'])\n",
    "protected_test = test['gender'].copy() \n",
    "y_test = test['income'].copy()\n",
    "x_test = test.drop(columns=['gender','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model to predict 'income'\n",
    "\n",
    "standard_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=4)    \n",
    "model_fit = standard_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92eee327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the training dataset : 90.09 %\n",
      "Model accuracy on the validation dataset : 86.75 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = standard_model.predict(x_train)\n",
    "y_valid_pred = standard_model.predict(x_valid)\n",
    "print('Model accuracy on the training dataset :', \n",
    "      round(100 * accuracy_score(y_train, y_train_pred),2),'%') # round the score to 2 digits  \n",
    "\n",
    "print('Model accuracy on the validation dataset :', \n",
    "      round(100 * accuracy_score(y_valid, y_valid_pred),2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae7ea2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf961655",
   "metadata": {},
   "source": [
    "# Log dataset & model snapshot to Etiq \n",
    "\n",
    "This is an example of how you log the already trained model to Etiq.\n",
    "\n",
    "When you log the dataset make sure you log a new sample or a test sample, not the sample you trained you model on. \n",
    "\n",
    "When you log the config, make sure the % for train and valid splits are 0. \n",
    "\n",
    "If you are planning to use this in production, not just pre-production get in touch with us. We will release integration demos shortly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e131e7",
   "metadata": {},
   "source": [
    "## Loading the config file \n",
    "\n",
    "The config is where you can set-up the scans you want, and the thresholds outside of which Etiq finds a problem. In the config you input relevant parameters (e.g. for bias/fairness scans you'll have to tell Etiq which feature is a demographic and which value represents a protected group). \n",
    "For more details on the config just check the documentation. You can upload these config files from wherever you want. We provide examples in the Demo repo with each notebook.   \n",
    "\n",
    "The config gets stored in the database so you can have a log and version control. \n",
    "\n",
    "When you log the config for an already trained model, please log \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ab3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.0, 1.0, 0.0],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.8],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_leakage': {'leakage_threshold': 0.85}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "etiq.load_config(\"./config_already_trained.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4216ef",
   "metadata": {},
   "source": [
    "## Log the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "\n",
    "#log your dataset\n",
    "\n",
    "dataset_loader = etiq.dataset(test)\n",
    "\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ebdfc",
   "metadata": {},
   "source": [
    "## Creating a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5277cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a snapshot\n",
    "snapshot = project.snapshots.create(name=\"Test Snapshot\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b43d3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107538d",
   "metadata": {},
   "source": [
    "# Run scans\n",
    "\n",
    "You can run multiple scans for snapshot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719e37e",
   "metadata": {},
   "source": [
    "## Bias Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3545fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0638:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.BiasMetricsIssuePipeline0638:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0638:Starting pipeline\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0638:Computed bias metrics for the dataset\n",
      "INFO:etiq.pipeline.BiasMetricsIssuePipeline0638:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_metrics\n",
    "\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830e8675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13b45c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demographic_parity_below_threshold</td>\n",
       "      <td>&lt;function demographic_parity at 0x7f8cef48d310&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demographic_parity_above_threshold</td>\n",
       "      <td>&lt;function demographic_parity at 0x7f8cef48d310&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equal_odds_tpr_below_threshold</td>\n",
       "      <td>&lt;function equal_odds_tpr at 0x7f8cef48d3a0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equal_odds_tpr_above_threshold</td>\n",
       "      <td>&lt;function equal_odds_tpr at 0x7f8cef48d3a0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>equal_odds_tnr_below_threshold</td>\n",
       "      <td>&lt;function equal_odds_tnr at 0x7f8cef48d430&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>equal_odds_tnr_above_threshold</td>\n",
       "      <td>&lt;function equal_odds_tnr at 0x7f8cef48d430&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>equal_opportunity_below_threshold</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f8cef48d4c0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>equal_opportunity_above_threshold</td>\n",
       "      <td>&lt;function equal_opportunity at 0x7f8cef48d4c0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>individual_fairness_below_threshold</td>\n",
       "      <td>&lt;function individual_fairness at 0x7f8cef48d700&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>individual_fairness_above_threshold</td>\n",
       "      <td>&lt;function individual_fairness at 0x7f8cef48d700&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0   demographic_parity_below_threshold   \n",
       "1   demographic_parity_above_threshold   \n",
       "2       equal_odds_tpr_below_threshold   \n",
       "3       equal_odds_tpr_above_threshold   \n",
       "4       equal_odds_tnr_below_threshold   \n",
       "5       equal_odds_tnr_above_threshold   \n",
       "6    equal_opportunity_below_threshold   \n",
       "7    equal_opportunity_above_threshold   \n",
       "8  individual_fairness_below_threshold   \n",
       "9  individual_fairness_above_threshold   \n",
       "\n",
       "                                             metric measure features segments  \\\n",
       "0   <function demographic_parity at 0x7f8cef48d310>    None       {}       {}   \n",
       "1   <function demographic_parity at 0x7f8cef48d310>    None       {}       {}   \n",
       "2       <function equal_odds_tpr at 0x7f8cef48d3a0>    None       {}       {}   \n",
       "3       <function equal_odds_tpr at 0x7f8cef48d3a0>    None       {}       {}   \n",
       "4       <function equal_odds_tnr at 0x7f8cef48d430>    None       {}       {}   \n",
       "5       <function equal_odds_tnr at 0x7f8cef48d430>    None       {}       {}   \n",
       "6    <function equal_opportunity at 0x7f8cef48d4c0>    None       {}       {}   \n",
       "7    <function equal_opportunity at 0x7f8cef48d4c0>    None       {}       {}   \n",
       "8  <function individual_fairness at 0x7f8cef48d700>    None       {}       {}   \n",
       "9  <function individual_fairness at 0x7f8cef48d700>    None       {}       {}   \n",
       "\n",
       "   total_issues_tested  issues_found   threshold  \n",
       "0                    1             0  [0.0, 0.2]  \n",
       "1                    1             0  [0.0, 0.2]  \n",
       "2                    1             0  [0.0, 0.2]  \n",
       "3                    1             0  [0.0, 0.2]  \n",
       "4                    1             0  [0.0, 0.2]  \n",
       "5                    1             0  [0.0, 0.2]  \n",
       "6                    1             0  [0.0, 0.2]  \n",
       "7                    1             0  [0.0, 0.2]  \n",
       "8                    1             0  [0.0, 0.8]  \n",
       "9                    1             0  [0.0, 0.8]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48df62",
   "metadata": {},
   "source": [
    "## Accuracy metrics scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432f8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0731:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0731:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0731:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0731:Computed acurracy metrics for the dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0731:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_below_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7f8cef48d160&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy_above_threshold</td>\n",
       "      <td>&lt;function accuracy at 0x7f8cef48d160&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true_pos_rate_below_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7f8cef48d1f0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_pos_rate_above_threshold</td>\n",
       "      <td>&lt;function true_pos_rate at 0x7f8cef48d1f0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true_neg_rate_below_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7f8cef48d280&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true_neg_rate_above_threshold</td>\n",
       "      <td>&lt;function true_neg_rate at 0x7f8cef48d280&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                                      metric  \\\n",
       "0       accuracy_below_threshold       <function accuracy at 0x7f8cef48d160>   \n",
       "1       accuracy_above_threshold       <function accuracy at 0x7f8cef48d160>   \n",
       "2  true_pos_rate_below_threshold  <function true_pos_rate at 0x7f8cef48d1f0>   \n",
       "3  true_pos_rate_above_threshold  <function true_pos_rate at 0x7f8cef48d1f0>   \n",
       "4  true_neg_rate_below_threshold  <function true_neg_rate at 0x7f8cef48d280>   \n",
       "5  true_neg_rate_above_threshold  <function true_neg_rate at 0x7f8cef48d280>   \n",
       "\n",
       "  measure features segments  total_issues_tested  issues_found   threshold  \n",
       "0    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "1    None       {}       {}                    1             0  [0.8, 1.0]  \n",
       "2    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "3    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "4    None       {}       {}                    1             0  [0.6, 1.0]  \n",
       "5    None       {}       {}                    1             0  [0.6, 1.0]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b6655",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566ceb9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b27bd",
   "metadata": {},
   "source": [
    "# Bias Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2beaf06",
   "metadata": {},
   "source": [
    "Even if your training and test samples are very similar, the bias sources are related to properties of the training dataset, not the test dataset. \n",
    "\n",
    "To run bias sources even if you have an already trained model please use the TRAINING dataset instead.\n",
    "\n",
    "You will need to change the train_test_valid in your config & then re-log your snapshots. You will still have the same model architecture from your already trained model, but if the scans show issues we recommend you clean your data and retrain the model. \n",
    "\n",
    "To be able to use bias sources you will have to log which features are categorical and which are numeric. \n",
    "\n",
    "You can do this in the config or in the notebook if easier. Commented out example shows you how to you do it in your notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9b863d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [1.0, 0.01, 0.0],\n",
       "  'cat_col': ['workclass',\n",
       "   'relationship',\n",
       "   'occupation',\n",
       "   'gender',\n",
       "   'race',\n",
       "   'native-country',\n",
       "   'marital-status',\n",
       "   'income',\n",
       "   'education'],\n",
       "  'cont_col': ['age',\n",
       "   'educational-num',\n",
       "   'fnlwgt',\n",
       "   'capital-gain',\n",
       "   'capital-loss',\n",
       "   'hours-per-week']},\n",
       " 'scan_bias_sources': {'auto': True},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.8],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_leakage': {'leakage_threshold': 0.85}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq.load_config(\"./config_already_trained_bias_sources.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d867c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "\n",
    "#log your dataset\n",
    "\n",
    "dataset_loader = etiq.dataset(train)\n",
    "\n",
    "\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "\n",
    "snapshot = project.snapshots.create(name=\"Test Snapshot\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1a3b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.DataPipeline0521:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0521:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0521:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0521:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0521:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0327:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0327:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0327:Start Phase IdentifyPipeline0622\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking proxy for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking correlation for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Checking Skew\n",
      "INFO:etiq.pipeline.IdentifyPipeline0622:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0327:Completed Phase IdentifyPipeline0622\n",
      "INFO:etiq.pipeline.DebiasPipeline0327:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0327:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "#scan_bias_sources\n",
    "\n",
    "# Run our pipelines\n",
    "(segments, issues, issue_summary) = snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23e1b266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [1.0, 0.01, 0.0],\n",
       "  'cat_col': 'cat_vars',\n",
       "  'cont_col': 'cont_vars'},\n",
       " 'scan_bias_sources': {'auto': True},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0]}},\n",
       " 'scan_bias_metrics': {'thresholds': {'equal_opportunity': [0.0, 0.2],\n",
       "   'demographic_parity': [0.0, 0.2],\n",
       "   'equal_odds_tnr': [0.0, 0.2],\n",
       "   'individual_fairness': [0.0, 0.8],\n",
       "   'equal_odds_tpr': [0.0, 0.2]}},\n",
       " 'scan_leakage': {'leakage_threshold': 0.85}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you want a shorter syntax for bias sources auto intead of using the config you can run the following:\n",
    "\n",
    "etiq.load_config(\"./config_already_trained_bias_sources2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daf9a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.DataPipeline0711:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.DataPipeline0711:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.DataPipeline0711:Starting pipeline\n",
      "INFO:etiq.pipeline.DataPipeline0711:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DataPipeline0711:Completed pipeline\n",
      "WARNING:etiq.pipeline.DebiasPipeline0375:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "INFO:etiq.pipeline.DebiasPipeline0375:Starting pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0375:Start Phase IdentifyPipeline0974\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Using parent model\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Starting pipeline\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature age\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature educational-num\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature fnlwgt\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature capital-gain\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature capital-loss\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature hours-per-week\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature race\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature relationship\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature native-country\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature occupation\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature education\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature marital-status\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking proxy for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking correlation for feature workclass\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Checking Skew\n",
      "INFO:etiq.pipeline.IdentifyPipeline0974:Completed pipeline\n",
      "INFO:etiq.pipeline.DebiasPipeline0375:Completed Phase IdentifyPipeline0974\n",
      "INFO:etiq.pipeline.DebiasPipeline0375:Computed metrics for the initial dataset\n",
      "INFO:etiq.pipeline.DebiasPipeline0375:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    name                                      business_rule  \\\n",
       " 0      0  `occupation` == 3 and `native-country` == 39 a...   \n",
       " 1      1            `occupation` == 14 and `workclass` == 4   \n",
       " 2      2      `occupation` == 13 and `native-country` == 39   \n",
       " 3      3                                  `occupation` == 6   \n",
       " 4      4  `occupation` == 4 and `native-country` == 39 a...   \n",
       " 5      5                                  `occupation` == 3   \n",
       " 6      6  `native-country` == 39 and `occupation` == 3 a...   \n",
       " 7      7  `native-country` == 39 and `occupation` == 3 a...   \n",
       " 8      8      `native-country` == 39 and `occupation` == 14   \n",
       " 9      9  `native-country` == 39 and `marital-status` ==...   \n",
       " 10    10  `native-country` == 39 and `marital-status` ==...   \n",
       " 11    11  `native-country` == 39 and `marital-status` ==...   \n",
       " 12    12                                                all   \n",
       " 13    13  `native-country` == 39 and `education` == 11 a...   \n",
       " 14    14      `native-country` == 39 and `occupation` == 13   \n",
       " 15    15  `native-country` == 39 and `marital-status` ==...   \n",
       " 16    16                                `relationship` == 0   \n",
       " 17    17                                `relationship` == 5   \n",
       " \n",
       "                                                  mask  \n",
       " 0   [False, False, False, False, False, True, Fals...  \n",
       " 1   [False, False, False, False, False, False, Fal...  \n",
       " 2   [False, False, False, False, False, False, Fal...  \n",
       " 3   [False, False, False, False, False, False, Fal...  \n",
       " 4   [True, False, False, False, False, False, Fals...  \n",
       " 5   [False, True, False, False, False, True, False...  \n",
       " 6   [False, False, False, False, False, True, Fals...  \n",
       " 7   [False, True, False, False, False, True, False...  \n",
       " 8   [False, False, False, False, False, False, Fal...  \n",
       " 9   [False, False, False, False, False, True, Fals...  \n",
       " 10  [False, False, False, False, False, True, Fals...  \n",
       " 11  [False, True, False, False, False, False, Fals...  \n",
       " 12  [True, True, True, True, True, True, True, Tru...  \n",
       " 13  [False, False, False, False, False, True, Fals...  \n",
       " 14  [False, False, False, False, False, False, Fal...  \n",
       " 15  [False, True, False, False, False, True, False...  \n",
       " 16  [True, True, True, False, True, True, False, F...  \n",
       " 17  [False, False, False, False, False, False, Fal...  ,\n",
       "                        name         feature  segment  \\\n",
       " 0         low_unpriv_sample            None      0.0   \n",
       " 1         low_unpriv_sample            None      1.0   \n",
       " 2         low_unpriv_sample            None      2.0   \n",
       " 3      skewed_unpriv_sample            None      2.0   \n",
       " 4         low_unpriv_sample            None      3.0   \n",
       " ..                      ...             ...      ...   \n",
       " 181       correlation_issue  marital-status     17.0   \n",
       " 182       correlation_issue       workclass     17.0   \n",
       " 183  limited_features_issue            None      2.0   \n",
       " 184  limited_features_issue            None      3.0   \n",
       " 185  limited_features_issue            None     14.0   \n",
       " \n",
       "                                    measure  measure_value  \\\n",
       " 0                                     None            NaN   \n",
       " 1                                     None            NaN   \n",
       " 2                                     None            NaN   \n",
       " 3                                     None            NaN   \n",
       " 4                                     None            NaN   \n",
       " ..                                     ...            ...   \n",
       " 181  <function corrcoef at 0x7f8d4c084b80>            NaN   \n",
       " 182  <function corrcoef at 0x7f8d4c084b80>            NaN   \n",
       " 183                                   None            NaN   \n",
       " 184                                   None            NaN   \n",
       " 185                                   None            NaN   \n",
       " \n",
       "                                              metric  metric_value   threshold  \n",
       " 0                                              None           NaN  (0.0, 0.8)  \n",
       " 1                                              None           NaN  (0.0, 0.8)  \n",
       " 2                                              None           NaN  (0.0, 0.8)  \n",
       " 3                                              None           NaN  (0.0, 0.2)  \n",
       " 4                                              None           NaN  (0.0, 0.8)  \n",
       " ..                                              ...           ...         ...  \n",
       " 181                                            None           NaN  (0.0, 0.2)  \n",
       " 182                                            None           NaN  (0.0, 0.2)  \n",
       " 183  <function equal_opportunity at 0x7f8cef48d4c0>      0.301989  (0.0, 0.2)  \n",
       " 184  <function equal_opportunity at 0x7f8cef48d4c0>      0.212121  (0.0, 0.2)  \n",
       " 185  <function equal_opportunity at 0x7f8cef48d4c0>      0.301989  (0.0, 0.2)  \n",
       " \n",
       " [186 rows x 8 columns],\n",
       "                      name                                          metric  \\\n",
       " 0          missing_sample                                            None   \n",
       " 1       low_unpriv_sample                                            None   \n",
       " 2         low_priv_sample                                            None   \n",
       " 3      skewed_priv_sample                                            None   \n",
       " 4    skewed_unpriv_sample                                            None   \n",
       " 5             proxy_issue                                            None   \n",
       " 6       correlation_issue                                            None   \n",
       " 7        low_volume_group                                            None   \n",
       " 8  limited_features_issue  <function equal_opportunity at 0x7f8cef48d4c0>   \n",
       " \n",
       "                                  measure  \\\n",
       " 0                                   None   \n",
       " 1                                   None   \n",
       " 2                                   None   \n",
       " 3                                   None   \n",
       " 4                                   None   \n",
       " 5  <function corrcoef at 0x7f8d4c084b80>   \n",
       " 6  <function corrcoef at 0x7f8d4c084b80>   \n",
       " 7                                   None   \n",
       " 8                                   None   \n",
       " \n",
       "                                             features  \\\n",
       " 0                                                 {}   \n",
       " 1                                                 {}   \n",
       " 2                                                 {}   \n",
       " 3                                                 {}   \n",
       " 4                                                 {}   \n",
       " 5                                     {relationship}   \n",
       " 6  {race, relationship, age, native-country, fnlw...   \n",
       " 7                                                 {}   \n",
       " 8                                                 {}   \n",
       " \n",
       "                                             segments  total_issues_tested  \\\n",
       " 0                                        {16, 17, 4}                   18   \n",
       " 1  {0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...                   15   \n",
       " 2                                                 {}                   15   \n",
       " 3                                               {11}                   13   \n",
       " 4                                            {2, 14}                   14   \n",
       " 5            {0, 2, 6, 7, 9, 10, 11, 12, 13, 14, 15}                  234   \n",
       " 6  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...                  234   \n",
       " 7                                                 {}                   18   \n",
       " 8                                   {2.0, 3.0, 14.0}                   18   \n",
       " \n",
       "    issues_found    threshold  \n",
       " 0             3   (0.0, 0.0)  \n",
       " 1            15   (0.0, 0.8)  \n",
       " 2             0   (0.0, 0.8)  \n",
       " 3             1   (0.0, 0.2)  \n",
       " 4             2   (0.0, 0.2)  \n",
       " 5            11   (0.0, 0.5)  \n",
       " 6           151   (0.0, 0.2)  \n",
       " 7             0  (1000, inf)  \n",
       " 8             3   (0.0, 0.2)  )"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#log your dataset\n",
    "\n",
    "dataset_loader = etiq.dataset(train)\n",
    "dl = etiq.dataset_loader.DatasetLoader(data=train, label='income', bias_params=dataset_loader.bias_params,\n",
    "                   train_valid_test_splits=[1.0, 0.01, 0.0], cat_col=cat_vars,\n",
    "                   cont_col=cont_vars, names_col = train.columns.values)\n",
    "\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "\n",
    "snapshot = project.snapshots.create(name=\"Test Snapshot\", dataset=dl.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n",
    "\n",
    "snapshot.scan_bias_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef710b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
