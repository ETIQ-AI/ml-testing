{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bee82c",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "  \n",
    "  \n",
    "### Snapshot 1, already-trained model \n",
    "\n",
    "\n",
    "  7. Load Adult dataset\n",
    "  \n",
    "  8. Train a model \n",
    "  \n",
    "  9. Load your config file and create your snapshot using the test dataset only \n",
    "  \n",
    "  10. Scan for bias rca issues \n",
    "  \n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe533c63",
   "metadata": {},
   "source": [
    "## What are Bias RCA scans?\n",
    "\n",
    "Some scans are simple tests that show whether a metric is above or below certain thresholds set by the user. Other scans are more complex and look at whether for a part of the sample dataset a metric is below or above the threshold. This will help you discover segments of customers or groups of records for which the model has a lower than expected accuracy or groups for which bias thresholds are not met.\n",
    "\n",
    "Imagine if your bias metrics tests have picked up issues, this test finds out exactly which segment has the issue, which should help you fix it sooner. If only a part of the data drifted or only a segment is underperforming, your overall tests might not pick up on it, but this test would. While you can pre-set segments you are interested in, if you just run the scan as is, it will discover problematic segments on its own.\n",
    "\n",
    "\n",
    "The RCA bias scans so far provide the following metrics out-of-the-box:\n",
    "\n",
    "1. Equal Opportunity: measures the difference in true positive rate between a privileged demographic group and an unprivileged demographic group.\n",
    "\n",
    "2. Demographic Parity: measures the difference between number of positive labels out of total from a privileged demographic group vs. a unprivileged demographic group)\n",
    "\n",
    "3. Equal Odds TNR: measures the difference between true negative rate - privileged vs. unprivileged. The full measure in the literature looks for an optimal point where the difference in true positive rate between demographic groups as well as the difference in true negative rate between demographic groups are both minimized.\n",
    "\n",
    "4. Individual Fairness: measures whether individuals with similar features observe the same model responses\n",
    "\n",
    "This test pipeline is experimental. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f8f3c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff524b3",
   "metadata": {},
   "source": [
    "# SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4d5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba75bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3951993118.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    etiq_login(\"https://dashboard.etiq.ai/\", <token>)\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from etiq import login as etiq_login\n",
    "etiq_login(\"https://dashboard.etiq.ai/\", <token>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Bias RCA Scans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f7699",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72d34b",
   "metadata": {},
   "source": [
    "# SNAPSHOT 1: xgboost, pre-configured model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e966368",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "\n",
    "First, we'll be encoding the categorical features found in this dataset.\n",
    "\n",
    "Second, we'll log the dataset to Etiq.\n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation.\n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE. Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. This is for example purposes\n",
    "\n",
    "Once model is built, we will:\n",
    " - log the relevant config to etiq \n",
    " - log the model together with the hold-out sample to etiq\n",
    " - run the accuracy rca scan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5532bbe",
   "metadata": {},
   "source": [
    "## Model Build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96378ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training/testing/validation datasets\n",
    "\n",
    "# separate into train/validate/test dataset of sizes 80%/10%/10% as percetages of the initial data\n",
    "data_remaining, test = train_test_split(data_encoded, test_size=0.1)\n",
    "train, valid = train_test_split(data_remaining, test_size=0.1112)\n",
    "\n",
    "# because we don't want to train on protected attributes or labels to be predicted, \n",
    "# let's remove these columns from the training dataset\n",
    "protected_train = train['gender'].copy() # gender is a protected attribute\n",
    "y_train = train['income'].copy() # labels we're going to train the model to predict\n",
    "x_train = train.drop(columns=['gender','income'])\n",
    "protected_valid = valid['gender'].copy() \n",
    "y_valid = valid['income'].copy() \n",
    "x_valid = valid.drop(columns=['gender','income'])\n",
    "protected_test = test['gender'].copy() \n",
    "y_test = test['income'].copy()\n",
    "x_test = test.drop(columns=['gender','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model to predict 'income'\n",
    "\n",
    "standard_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=4)    \n",
    "model_fit = standard_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b990c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = standard_model.predict(x_train)\n",
    "y_valid_pred = standard_model.predict(x_valid)\n",
    "print('Model accuracy on the training dataset :', \n",
    "      round(100 * accuracy_score(y_train, y_train_pred),2),'%') # round the score to 2 digits  \n",
    "\n",
    "print('Model accuracy on the validation dataset :', \n",
    "      round(100 * accuracy_score(y_valid, y_valid_pred),2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f55aa6",
   "metadata": {},
   "source": [
    "## Add a Custom Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@etiq.metrics.bias_metric\n",
    "@etiq.custom_metric\n",
    "@etiq.actual_values(\"actual\")\n",
    "@etiq.prediction_values(\"predictions\")\n",
    "@etiq.positive_outcome(\"positive_outcome_label\")\n",
    "@etiq.negative_outcome(\"negative_outcome_label\")\n",
    "\n",
    "def treatment_equality(predictions, actual, positive_outcome_label, negative_outcome_label):\n",
    "    false_neg = sum((predictions != actual) & (predictions == negative_outcome_label))\n",
    "    false_pos = sum((predictions != actual) & (predictions == positive_outcome_label))\n",
    "    \n",
    "    return false_pos/false_neg - false_pos/false_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a76dc",
   "metadata": {},
   "source": [
    "## Log config, dataset and model to Etiq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a6d3a",
   "metadata": {},
   "source": [
    "For already trained models make sure you only you use a sample you held out. \n",
    "\n",
    "As you don't want any retraining of the model to occur, set your train_valid_test split to [0.0, 1.0, 0.0]. \n",
    "\n",
    "In this instance we have used a low volume for the minimum segment size to illustrate the issues, but you should probably set it higher, depending on your use case and sample size. Also we have set the threshold for bias low so as to make sure it finds at least one issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "with etiq.etiq_config(\"./config_bias_rca.json\"):\n",
    "    #log your dataset (the sample you held-out!!!)\n",
    "    dataset = etiq.BiasDatasetBuilder.dataset(test)\n",
    "    \n",
    "    #Log your already trained model\n",
    "\n",
    "    model = Model(model_fitted=model_fit)\n",
    "    \n",
    "    # Create the snapshot\n",
    "    snapshot = project.snapshots.create(name=\"Snapshot 1\", \n",
    "                                        dataset=dataset,\n",
    "                                        model=model, \n",
    "                                        bias_params=etiq.biasparams.BiasParams(protected='gender', \n",
    "                                                                               privileged=1, \n",
    "                                                                               unprivileged=0, \n",
    "                                                                               positive_outcome_label=1, \n",
    "                                                                               negative_outcome_label=0)\n",
    "                                       )\n",
    "    print(\"Running Bias Scan... \\n\")\n",
    "    (segments_bias, issues_bias, issue_summary_bias) = snapshot.scan_bias_metrics()\n",
    "    print(\"\\n Running RCA Bias Scan... \\n\")\n",
    "    (segments_bias_rca, issues_bias_rca, issue_summary_bias_rca)  = snapshot.scan_bias_metrics_rca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24800227",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_summary_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546fdbd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da569de",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961aa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_summary_bias_rca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98126af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_bias_rca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_bias_rca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff015060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
