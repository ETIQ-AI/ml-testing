{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "  \n",
    "### Custom Metrics Scans\n",
    "\n",
    "\n",
    "  4. Load Adult dataset and train a model\n",
    "  \n",
    "  5. Create a custom metric \n",
    "  \n",
    "  6. Add your new metric to the config file\n",
    "  \n",
    "  5. Load your config file and create your snapshot based on the model you've just trained\n",
    "  \n",
    "  6. Scan for accuracy issues, including your custom metric scan \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why custom metrics?\n",
    "\n",
    "From talking to data scientists and being data scientists ourselves, we know that a specific use case and company requires perhaps a different set of metrics than another. \n",
    "\n",
    "This functionality allows you to add your custom metrics to the scan suite and run your scan as you would with out-of-the-box metrics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import etiq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import login as etiq_login\n",
    "# etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Custom Metrics Scans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOM METRICS SCANS: xgboost, already trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "\n",
    "First, we'll be encoding the categorical features found in this dataset.\n",
    "\n",
    "Second, we'll log the dataset to Etiq.\n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset, This allows us to encode prior to splitting into train/test/validation.\n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE.\n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding use one hot encoding. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdata\")\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training/testing/validation datasets\n",
    "\n",
    "# separate into train/validate/test dataset of sizes 80%/10%/10% as percetages of the initial data\n",
    "data_remaining, test = train_test_split(data_encoded, test_size=0.1)\n",
    "train, valid = train_test_split(data_remaining, test_size=0.1112)\n",
    "\n",
    "# because we don't want to train on protected attributes or labels to be predicted, \n",
    "# let's remove these columns from the training dataset\n",
    "protected_train = train['gender'].copy() # gender is a protected attribute\n",
    "y_train = train['income'].copy() # labels we're going to train the model to predict\n",
    "x_train = train.drop(columns=['gender','income'])\n",
    "protected_valid = valid['gender'].copy() \n",
    "y_valid = valid['income'].copy() \n",
    "x_valid = valid.drop(columns=['gender','income'])\n",
    "protected_test = test['gender'].copy() \n",
    "y_test = test['income'].copy()\n",
    "x_test = test.drop(columns=['gender','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model to predict 'income'\n",
    "\n",
    "standard_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=4)    \n",
    "model_fit = standard_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the training dataset : 90.21 %\n",
      "Model accuracy on the validation dataset : 86.48 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = standard_model.predict(x_train)\n",
    "y_valid_pred = standard_model.predict(x_valid)\n",
    "print('Model accuracy on the training dataset :', \n",
    "      round(100 * accuracy_score(y_train, y_train_pred),2),'%') # round the score to 2 digits  \n",
    "\n",
    "print('Model accuracy on the validation dataset :', \n",
    "      round(100 * accuracy_score(y_valid, y_valid_pred),2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your custom accuracy metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment the decorators you can use to build your custom metric are as follows:\n",
    "\n",
    "- prediction_values (refers to what the model scores, should be a list)\n",
    "\n",
    "- actual_values (refers to the actuals, if your custom metric is for production, it will use the score as actual if it is   provided and no actuals or model are available, should be a list)\n",
    "\n",
    "- protected_values (refers to the demographic variable you want to check for bias, if you have multiple demographics please create a feature with the intersection)\n",
    "\n",
    "- positive_outcome (directional, refers to what is considered a positive prediction or outcome, e.g. in the case of a lending model it would be a low risk score or if the customer is accepted for the loan, should be a value)\n",
    "\n",
    "- negative_outcome (directional, refers to what is considered a negative prediction or outcome, e.g. in the case of a lending model it would be a high risk score or if the customer is rejected for the loan, should be a value)\n",
    "\n",
    "- privileged_class (refers to the class in the demographics which is priviledged - not protected by the legislation, should be a value)\n",
    "\n",
    "- unprivileged_class (refers to the class in the demographics which is not priviledged - and which is protected by the legislation, should be a value, in future releases we will add functionality for multiple values here)\n",
    "\n",
    "They follow the parameters available in the config file. \n",
    "\n",
    "Below is an example syntax of how you could use these decorators.\n",
    "\n",
    "@etiq.metrics.accuracy_metric - refers to logging your metric as an accuracy metric (right now you can log it either as accuracy or as bias metric, with drift pending)\n",
    "\n",
    "@etiq.custom_metric - specifies that this is a custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "@etiq.metrics.accuracy_metric\n",
    "@etiq.custom_metric\n",
    "@etiq.actual_values('actual')\n",
    "@etiq.prediction_values('predictions')\n",
    "\n",
    "def accuracy_custom(predictions=None, actual=None):\n",
    "    \"\"\" Accuracy = nr of correct predictions/ nr of predictions\n",
    "    \"\"\"\n",
    "    apred = np.asarray(predictions)\n",
    "    alabel = np.asarray(actual)\n",
    "    return (apred == alabel).mean()\n",
    "\n",
    "\n",
    "@etiq.metrics.accuracy_metric\n",
    "@etiq.custom_metric\n",
    "@etiq.actual_values('actual')\n",
    "@etiq.prediction_values('predictions')\n",
    "@etiq.positive_outcome(\"positive_outcome_label\")\n",
    "@etiq.negative_outcome(\"negative_outcome_label\")\n",
    "def recall(predictions, actual, positive_outcome_label, negative_outcome_label):\n",
    "    \"\"\"\n",
    "        Recall (Sensitivity)is the ratio of True Positives to all the positives in your Dataset.\n",
    "        recall = TP/(TP+FN)\n",
    "    \"\"\"\n",
    "    true_pos = sum((predictions == actual) & (actual == positive_outcome_label))\n",
    "    false_neg = sum((predictions != actual) & (actual == negative_outcome_label))\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    return recall\n",
    "\n",
    "\n",
    "\n",
    "@etiq.metrics.accuracy_metric\n",
    "@etiq.custom_metric\n",
    "@etiq.actual_values('actual')\n",
    "@etiq.prediction_values('predictions')\n",
    "@etiq.positive_outcome(\"positive_outcome_label\")\n",
    "def precision(predictions, actual, positive_outcome_label):\n",
    "    \"\"\"\n",
    "        Precision is the ratio of True Positives to all the positives predicted by the model\n",
    "        precision = TP/(TP+FP)\n",
    "    \"\"\"\n",
    "    true_pos = sum((predictions == actual) & (actual == positive_outcome_label))\n",
    "    false_pos = sum((predictions != actual) & (actual == positive_outcome_label))\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.5}\n",
      "{'precision': 0.6666666666666666}\n",
      "{'accuracy_custom': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#check with a short example\n",
    "\n",
    "pred = np.asarray([1, 1, 1, 0, 0, 1])\n",
    "label = np.asarray([1, 0, 1, 0, 1, 0])\n",
    "res = accuracy_custom(pred=pred, label=label)\n",
    "recall = recall(predictions=pred, actual=label, positive_outcome_label=1, negative_outcome_label=0)\n",
    "print(recall)\n",
    "\n",
    "precision = precision(predictions=pred, actual=label, positive_outcome_label=1)\n",
    "print(precision)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log config, dataset and model to Etiq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For already trained models make sure you only you use a sample you held out. \n",
    "\n",
    "As you don't want any retraining of the model to occur, set your train_valid_test split to [0.0, 1.0, 0.0].\n",
    "\n",
    "Don't forget to add the new metric to your config file!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'label': 'income',\n",
       "  'bias_params': {'protected': 'gender',\n",
       "   'privileged': 1,\n",
       "   'unprivileged': 0,\n",
       "   'positive_outcome_label': 1,\n",
       "   'negative_outcome_label': 0},\n",
       "  'train_valid_test_splits': [0.0, 1.0, 0.0]},\n",
       " 'scan_accuracy_metrics': {'thresholds': {'accuracy': [0.8, 1.0],\n",
       "   'true_pos_rate': [0.6, 1.0],\n",
       "   'true_neg_rate': [0.6, 1.0],\n",
       "   'accuracy_custom': [0.9, 1.0],\n",
       "   'recall': [0.85, 1.0],\n",
       "   'precision': [0.85, 1.0]}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq.load_config(\"./config_accuracy_custom.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "\n",
    "#log your dataset (the sample you held-out!!!)\n",
    "\n",
    "dataset_loader = etiq.dataset(test)\n",
    "\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_fitted=model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Created histogram summary of data (15 fields)\n"
     ]
    }
   ],
   "source": [
    "snapshot = project.snapshots.create(name=\"New custom accuracy metric\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Computed acurracy metrics for the dataset {'accuracy': 0.87, 'true_pos_rate': 0.6496655518394648, 'true_neg_rate': 0.9349417186229331, 'accuracy_custom': 0.8650972364380758, 'recall': 0.7640117994100295, 'precision': 0.6496655518394648}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Issue Aggregate = {'accuracy_below_threshold': IssueAggregate(name='accuracy_below_threshold', metric=<compiled_function accuracy at 0x14c20fd30>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_pos_rate_below_threshold': IssueAggregate(name='true_pos_rate_below_threshold', metric=<compiled_function true_pos_rate at 0x14c20fe20>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_neg_rate_below_threshold': IssueAggregate(name='true_neg_rate_below_threshold', metric=<compiled_function true_neg_rate at 0x14c510040>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'accuracy_custom_below_threshold': IssueAggregate(name='accuracy_custom_below_threshold', metric=<compiled_function accuracy_custom at 0x14d801540>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'recall_below_threshold': IssueAggregate(name='recall_below_threshold', metric=<compiled_function recall at 0x1117ac840>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'precision_below_threshold': IssueAggregate(name='precision_below_threshold', metric=<compiled_function precision at 0x14d801440>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0))}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Threshold (0.8, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Threshold (0.9, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Threshold (0.85, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Threshold (0.85, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0026:Completed pipeline\n"
     ]
    }
   ],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>feature</th>\n",
       "      <th>segment</th>\n",
       "      <th>measure</th>\n",
       "      <th>measure_value</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_custom_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;compiled_function accuracy_custom at 0x14d801...</td>\n",
       "      <td>0.865097</td>\n",
       "      <td>(0.9, 1.0)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;compiled_function recall at 0x1117ac840&gt;</td>\n",
       "      <td>0.764012</td>\n",
       "      <td>(0.85, 1.0)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision_below_threshold</td>\n",
       "      <td>None</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;compiled_function precision at 0x14d801440&gt;</td>\n",
       "      <td>0.649666</td>\n",
       "      <td>(0.85, 1.0)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name feature segment measure  measure_value  \\\n",
       "0  accuracy_custom_below_threshold    None     all    None            NaN   \n",
       "1           recall_below_threshold    None     all    None            NaN   \n",
       "2        precision_below_threshold    None     all    None            NaN   \n",
       "\n",
       "                                              metric  metric_value  \\\n",
       "0  <compiled_function accuracy_custom at 0x14d801...      0.865097   \n",
       "1          <compiled_function recall at 0x1117ac840>      0.764012   \n",
       "2       <compiled_function precision at 0x14d801440>      0.649666   \n",
       "\n",
       "     threshold value  \n",
       "0   (0.9, 1.0)  None  \n",
       "1  (0.85, 1.0)  None  \n",
       "2  (0.85, 1.0)  None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>measure</th>\n",
       "      <th>features</th>\n",
       "      <th>segments</th>\n",
       "      <th>total_issues_tested</th>\n",
       "      <th>issues_found</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_below_threshold</td>\n",
       "      <td>&lt;compiled_function accuracy at 0x14c20fd30&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.85, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_pos_rate_below_threshold</td>\n",
       "      <td>&lt;compiled_function true_pos_rate at 0x14c20fe20&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.85, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true_neg_rate_below_threshold</td>\n",
       "      <td>&lt;compiled_function true_neg_rate at 0x14c510040&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.85, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy_custom_below_threshold</td>\n",
       "      <td>&lt;compiled_function accuracy_custom at 0x14d801...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{all}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.85, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall_below_threshold</td>\n",
       "      <td>&lt;compiled_function recall at 0x1117ac840&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{all}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.85, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision_below_threshold</td>\n",
       "      <td>&lt;compiled_function precision at 0x14d801440&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>{all}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.85, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "0         accuracy_below_threshold   \n",
       "1    true_pos_rate_below_threshold   \n",
       "2    true_neg_rate_below_threshold   \n",
       "3  accuracy_custom_below_threshold   \n",
       "4           recall_below_threshold   \n",
       "5        precision_below_threshold   \n",
       "\n",
       "                                              metric measure features  \\\n",
       "0        <compiled_function accuracy at 0x14c20fd30>    None       {}   \n",
       "1   <compiled_function true_pos_rate at 0x14c20fe20>    None       {}   \n",
       "2   <compiled_function true_neg_rate at 0x14c510040>    None       {}   \n",
       "3  <compiled_function accuracy_custom at 0x14d801...    None       {}   \n",
       "4          <compiled_function recall at 0x1117ac840>    None       {}   \n",
       "5       <compiled_function precision at 0x14d801440>    None       {}   \n",
       "\n",
       "  segments  total_issues_tested  issues_found    threshold  \n",
       "0       {}                    1             0  [0.85, 1.0]  \n",
       "1       {}                    1             0  [0.85, 1.0]  \n",
       "2       {}                    1             0  [0.85, 1.0]  \n",
       "3    {all}                    1             1  [0.85, 1.0]  \n",
       "4    {all}                    1             1  [0.85, 1.0]  \n",
       "5    {all}                    1             1  [0.85, 1.0]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your custom bias metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "@etiq.metrics.bias_metric\n",
    "@etiq.custom_metric\n",
    "@etiq.prediction_values('predictions')\n",
    "def gini_index(predictions):\n",
    "    class_counts = Counter(predictions)\n",
    "    num_values = len(predictions)\n",
    "    sum_probs = 0.0\n",
    "    for aclass in class_counts:\n",
    "        sum_probs += (class_counts[aclass]/num_values) ** 2\n",
    "    return 1.0 - sum_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log config, dataset and model to Etiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiq.load_config(\"./config_bias_custom.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import Model\n",
    "\n",
    "\n",
    "#log your dataset (the sample you held-out!!!)\n",
    "\n",
    "dataset_loader = etiq.dataset(test)\n",
    "\n",
    "#Log your already trained model\n",
    "\n",
    "model = Model(model_fitted=model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = project.snapshots.create(name=\"New custom bias metric\", dataset=dataset_loader.initial_dataset, model=model, bias_params=dataset_loader.bias_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(segments, issues, issue_summary) = snapshot.scan_bias_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etiq-1.3.7.1",
   "language": "python",
   "name": "etiq-1.3.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
