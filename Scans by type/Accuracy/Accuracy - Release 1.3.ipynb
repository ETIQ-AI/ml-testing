{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary \n",
    "\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "  1. Import etiq library - for install please check our docs (https://docs.etiq.ai/) \n",
    "\n",
    "  2. Login to the dashboard - this way you can send the results to your dashboard instance (Etiq AWS instance if you use the SaaS version). To deploy on your own cloud instance, get in touch (info@etiq.ai)\n",
    "\n",
    "  3. Create or open a project \n",
    "  \n",
    "  \n",
    "### Snapshot 1, pre-configured model \n",
    "\n",
    "\n",
    "  4. Load Adult dataset \n",
    "  \n",
    "  5. Load your config file and create your snapshot based on an etiq wrapped xgboost model\n",
    "  \n",
    "  6. Scan for accuracy issues \n",
    "  \n",
    "  \n",
    "  \n",
    "### Snapshot 2, already-trained model \n",
    "\n",
    "\n",
    "  7. Load Adult dataset\n",
    "  \n",
    "  8. Train a model \n",
    "  \n",
    "  9. Load your config file and create your snapshot using the test dataset only \n",
    "  \n",
    "  10. Scan for accuracy issues \n",
    "  \n",
    "  \n",
    "### Snapshot 3, in production\n",
    "\n",
    "\n",
    "  7. Load Adult dataset & use the already trained model from the previous snapshot \n",
    "  \n",
    "  9. Load your config file and create your snapshot using the test dataset  with the 'label' feature assumed to be actuals\n",
    "  \n",
    "  10. Scan for accuracy issues \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why run accuracy scans?\n",
    "\n",
    "Accuracy is what I optimize my models on. Why should I have tests on accuracy metrics as well?\n",
    "\n",
    "- High accuracy can be indicative of a problem, just as much as low accuracy is. For instance, if a plain accuracy metric is 10% higher than you've expected, you might have leakage somewhere or another issue.\n",
    "\n",
    "- Optimizing for a metric pre-production does not equate to optimizing for that metric in production. You will be better off getting a good model off the ground, a model with no obvious issues, and which is likely to be robust, than trying to achieve a 1% accuracy with an overfitting model, a model which is unfairly discriminating against protected demographic groups or with a model that will experience abrupt performance decay. \n",
    "\n",
    "\n",
    "Our accuracy scans so far provide 3 metrics: \n",
    "\n",
    "1. accuracy - % correct out of total \n",
    "\n",
    "2. true positive rate - the proportion positive outcome labels that are correctly classified out of all positive outcome labels\n",
    "\n",
    "3. true negative rate -  the proportion negative outcome labels that are correctly classified out of all negative outcome labels\n",
    "\n",
    "\n",
    "But you can use custom metrics to add your own metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for trying out the ETIQ.ai toolkit!\n",
      "\n",
      "Visit our getting started documentation at https://docs.etiq.ai/\n",
      "\n",
      "Visit our Slack channel at https://etiqcore.slack.com/ for support or feedback.\n",
      "\n",
      "Requirement already satisfied: Jinja2 in /Users/yelyzavetadatsenko/NewVirtEnv2/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yelyzavetadatsenko/NewVirtEnv2/lib/python3.10/site-packages (from Jinja2) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import etiq\n",
    "\n",
    "%pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce2b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# styling the issue_summary \n",
    "\n",
    "# making sure it shows the name or None\n",
    "def metric_format(v):\n",
    "    if v is not None:\n",
    "        return v.__name__\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def threshold_format(v):\n",
    "    return f'{v[0]} - {v[1]}'\n",
    "\n",
    "def set_format(v):\n",
    "    if len(v) == 0:\n",
    "        return 'None'\n",
    "    return f'{v}'\n",
    "\n",
    "# highlighting the row with the issue\n",
    "def highlight_rows(row):\n",
    "    value = row.loc['issues_found']\n",
    "    if value > 0:\n",
    "        color = '#FFB3BA' # Red\n",
    "    else:\n",
    "        color = '#BAFFC9' # Green\n",
    "    return ['background-color: {}'.format(color) for r in row]\n",
    "\n",
    "# visuals: first column white\n",
    "def backround_first_column(col):\n",
    "    color = 'white'\n",
    "    return ['background-color: {}'.format(color) for c in col]\n",
    "\n",
    "# font color - black\n",
    "def font_color(v):\n",
    "    color = 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "# complete function for issue_summary\n",
    "def issue_summary_pretty(styler):\n",
    "    styler.format(metric_format, subset=['metric', 'measure'])\n",
    "    styler.format(threshold_format, subset=['threshold'])\n",
    "    styler.format(set_format, subset=['features', 'segments'])\n",
    "    styler.hide(axis=\"index\")\n",
    "    styler.apply(highlight_rows, axis=1)\n",
    "    styler.apply(backround_first_column, axis='columns', subset=['name'])\n",
    "    styler.applymap(font_color)\n",
    "    styler.set_caption(\"Issues Summary\")\n",
    "    return styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq import login as etiq_login\n",
    "# etiq_login(\"https://dashboard.etiq.ai/\", \"<token>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get/create a single named project\n",
    "project = etiq.projects.open(name=\"Accuracy Scans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNAPSHOT 1: xgboost, pre-configured model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate some of the library's features, we build a model that predicts whether an applicant makes over or under 50K using the Adult dataset from https://archive.ics.uci.edu/ml/datasets/adult.\n",
    "\n",
    "\n",
    "First, we'll be encoding the categorical features found in this dataset.\n",
    "\n",
    "Second, we'll log the dataset to Etiq.\n",
    "\n",
    "In this case we encode prior to splitting into test/train/validate because we know in advance the categories people fall into for this dataset. This means that in production we won't run into new categories that will fall into a bucket not included in this dataset.\n",
    "\n",
    "However if this is not the case for your use case, you should NOT encode prior to splitting your sample, as this might lead to LEAKAGE.\n",
    "\n",
    "Encoding categorical values itself is problematic as it assigns a numerical ranking to categorical variables. For best practice encoding, use one-hot encoding which converts each categorical value into a new categorical column and assigns a binary value of 0 or 1 to those columns. As we limit the free library functionality to 15 features, we will not do one-hot encoding for the purposes of this example.\n",
    "\n",
    "Remember: This is an example only. The use case for the majority of scans in Etiq is that you log the model to Etiq once you have the sample that you'll be training on. Usually this sample will have numeric features only, as otherwise you will not be able to use it in with the majority of supported libraries training methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdataset.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etiq.transforms import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>relationship</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>income</th>\n",
       "      <th>education</th>\n",
       "      <th>workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>226802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>89814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>336951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>160323</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>103497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>257302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>154374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>151910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>201490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>287927</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  educational-num  fnlwgt  capital-gain  capital-loss  \\\n",
       "0       25                7  226802             0             0   \n",
       "1       38                9   89814             0             0   \n",
       "2       28               12  336951             0             0   \n",
       "3       44               10  160323          7688             0   \n",
       "4       18               10  103497             0             0   \n",
       "...    ...              ...     ...           ...           ...   \n",
       "48837   27               12  257302             0             0   \n",
       "48838   40                9  154374             0             0   \n",
       "48839   58                9  151910             0             0   \n",
       "48840   22                9  201490             0             0   \n",
       "48841   52                9  287927         15024             0   \n",
       "\n",
       "       hours-per-week  native-country  occupation  race  relationship  gender  \\\n",
       "0                  40              39           7     2             3       1   \n",
       "1                  50              39           5     4             0       1   \n",
       "2                  40              39          11     4             0       1   \n",
       "3                  40              39           7     2             0       1   \n",
       "4                  30              39           0     4             3       0   \n",
       "...               ...             ...         ...   ...           ...     ...   \n",
       "48837              38              39          13     4             5       0   \n",
       "48838              40              39           7     4             0       1   \n",
       "48839              40              39           1     4             4       0   \n",
       "48840              20              39           1     4             3       1   \n",
       "48841              40              39           4     4             5       0   \n",
       "\n",
       "       marital-status  income  education  workclass  \n",
       "0                   4       0          1          4  \n",
       "1                   2       0         11          4  \n",
       "2                   2       1          7          2  \n",
       "3                   2       1         15          4  \n",
       "4                   4       0         15          0  \n",
       "...               ...     ...        ...        ...  \n",
       "48837               2       0          7          4  \n",
       "48838               2       1         11          4  \n",
       "48839               6       0         11          4  \n",
       "48840               4       0         11          4  \n",
       "48841               2       1         11          5  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Make per-project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the snapshot to Etiq \n",
    "\n",
    "This can happen at any point in the pipeline and through a variety of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yelyzavetadatsenko/NewVirtEnv2/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Created histogram summary of data (15 fields)\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Computed acurracy metrics for the dataset {'accuracy': 0.87, 'true_pos_rate': 0.6690328305235137, 'true_neg_rate': 0.9302820649281532}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Issue Aggregate = {'accuracy_below_threshold': IssueAggregate(name='accuracy_below_threshold', metric=<compiled_function accuracy at 0x14ee37f10>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_pos_rate_below_threshold': IssueAggregate(name='true_pos_rate_below_threshold', metric=<compiled_function true_pos_rate at 0x14eeec040>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_neg_rate_below_threshold': IssueAggregate(name='true_neg_rate_below_threshold', metric=<compiled_function true_neg_rate at 0x14eeec130>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0))}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Threshold (0.8, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Threshold (0.7, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0448:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fb944_row0_col0, #T_fb944_row2_col0 {\n",
       "  background-color: #BAFFC9;\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "}\n",
       "#T_fb944_row0_col1, #T_fb944_row0_col2, #T_fb944_row0_col3, #T_fb944_row0_col4, #T_fb944_row0_col5, #T_fb944_row0_col6, #T_fb944_row0_col7, #T_fb944_row2_col1, #T_fb944_row2_col2, #T_fb944_row2_col3, #T_fb944_row2_col4, #T_fb944_row2_col5, #T_fb944_row2_col6, #T_fb944_row2_col7 {\n",
       "  background-color: #BAFFC9;\n",
       "  color: black;\n",
       "}\n",
       "#T_fb944_row1_col0 {\n",
       "  background-color: #FFB3BA;\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "}\n",
       "#T_fb944_row1_col1, #T_fb944_row1_col2, #T_fb944_row1_col3, #T_fb944_row1_col4, #T_fb944_row1_col5, #T_fb944_row1_col6, #T_fb944_row1_col7 {\n",
       "  background-color: #FFB3BA;\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fb944\">\n",
       "  <caption>Issues Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_fb944_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_fb944_level0_col1\" class=\"col_heading level0 col1\" >metric</th>\n",
       "      <th id=\"T_fb944_level0_col2\" class=\"col_heading level0 col2\" >measure</th>\n",
       "      <th id=\"T_fb944_level0_col3\" class=\"col_heading level0 col3\" >features</th>\n",
       "      <th id=\"T_fb944_level0_col4\" class=\"col_heading level0 col4\" >segments</th>\n",
       "      <th id=\"T_fb944_level0_col5\" class=\"col_heading level0 col5\" >total_issues_tested</th>\n",
       "      <th id=\"T_fb944_level0_col6\" class=\"col_heading level0 col6\" >issues_found</th>\n",
       "      <th id=\"T_fb944_level0_col7\" class=\"col_heading level0 col7\" >threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_fb944_row0_col0\" class=\"data row0 col0\" >accuracy_below_threshold</td>\n",
       "      <td id=\"T_fb944_row0_col1\" class=\"data row0 col1\" >accuracy</td>\n",
       "      <td id=\"T_fb944_row0_col2\" class=\"data row0 col2\" >None</td>\n",
       "      <td id=\"T_fb944_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_fb944_row0_col4\" class=\"data row0 col4\" >None</td>\n",
       "      <td id=\"T_fb944_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_fb944_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_fb944_row0_col7\" class=\"data row0 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb944_row1_col0\" class=\"data row1 col0\" >true_pos_rate_below_threshold</td>\n",
       "      <td id=\"T_fb944_row1_col1\" class=\"data row1 col1\" >true_pos_rate</td>\n",
       "      <td id=\"T_fb944_row1_col2\" class=\"data row1 col2\" >None</td>\n",
       "      <td id=\"T_fb944_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_fb944_row1_col4\" class=\"data row1 col4\" >{'all'}</td>\n",
       "      <td id=\"T_fb944_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "      <td id=\"T_fb944_row1_col6\" class=\"data row1 col6\" >1</td>\n",
       "      <td id=\"T_fb944_row1_col7\" class=\"data row1 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb944_row2_col0\" class=\"data row2 col0\" >true_neg_rate_below_threshold</td>\n",
       "      <td id=\"T_fb944_row2_col1\" class=\"data row2 col1\" >true_neg_rate</td>\n",
       "      <td id=\"T_fb944_row2_col2\" class=\"data row2 col2\" >None</td>\n",
       "      <td id=\"T_fb944_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_fb944_row2_col4\" class=\"data row2 col4\" >None</td>\n",
       "      <td id=\"T_fb944_row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "      <td id=\"T_fb944_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_fb944_row2_col7\" class=\"data row2 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150237430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq.model import DefaultXGBoostClassifier\n",
    "\n",
    "with etiq.etiq_config('config_accuracy.json'):\n",
    "    #load your dataset\n",
    "\n",
    "    dataset = etiq.BiasDatasetBuilder.dataset(data_encoded)\n",
    "\n",
    "    # Load our model\n",
    "    model = DefaultXGBoostClassifier()\n",
    "\n",
    "    # Creating a snapshot\n",
    "    snapshot = project.snapshots.create(name=\"Snapshot 1\", \n",
    "                                        dataset=dataset, \n",
    "                                        model=model, \n",
    "                                        bias_params=etiq.biasparams.BiasParams(protected='gender', privileged=1, unprivileged=0, positive_outcome_label=1, negative_outcome_label=0))\n",
    "    \n",
    "    #accuracy metrics scan\n",
    "    (segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()\n",
    "\n",
    "# issue_summary\n",
    "\n",
    "issue_summary.style.pipe(issue_summary_pretty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Metrics Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNAPSHOT 2, already trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading a dataset. We're using the adult dataset\n",
    "data = etiq.utils.load_sample(\"adultdataset.csv\")\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a LabelEncoder to transform categorical variables\n",
    "cont_vars = ['age', 'educational-num', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_vars = list(set(data.columns.values) - set(cont_vars))\n",
    "\n",
    "label_encoders = {}\n",
    "data_encoded = pd.DataFrame()\n",
    "for i in cat_vars:\n",
    "    label = LabelEncoder()\n",
    "    data_encoded[i] = label.fit_transform(data[i])\n",
    "    label_encoders[i] = label\n",
    "\n",
    "data_encoded.set_index(data.index, inplace=True)\n",
    "data_encoded = pd.concat([data.loc[:, cont_vars], data_encoded], axis=1).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training/testing/validation datasets\n",
    "\n",
    "# separate into train/validate/test dataset of sizes 80%/10%/10% as percetages of the initial data\n",
    "data_remaining, test = train_test_split(data_encoded, test_size=0.1)\n",
    "train, valid = train_test_split(data_remaining, test_size=0.1112)\n",
    "\n",
    "# because we don't want to train on protected attributes or labels to be predicted, \n",
    "# let's remove these columns from the training dataset\n",
    "protected_train = train['gender'].copy() # gender is a protected attribute\n",
    "y_train = train['income'].copy() # labels we're going to train the model to predict\n",
    "x_train = train.drop(columns=['gender','income'])\n",
    "protected_valid = valid['gender'].copy() \n",
    "y_valid = valid['income'].copy() \n",
    "x_valid = valid.drop(columns=['gender','income'])\n",
    "protected_test = test['gender'].copy() \n",
    "y_test = test['income'].copy()\n",
    "x_test = test.drop(columns=['gender','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model to predict 'income'\n",
    "\n",
    "standard_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=4)    \n",
    "model_fit = standard_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the training dataset : 90.05 %\n",
      "Model accuracy on the validation dataset : 87.67 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = standard_model.predict(x_train)\n",
    "y_valid_pred = standard_model.predict(x_valid)\n",
    "print('Model accuracy on the training dataset :', \n",
    "      round(100 * accuracy_score(y_train, y_train_pred),2),'%') # round the score to 2 digits  \n",
    "\n",
    "print('Model accuracy on the validation dataset :', \n",
    "      round(100 * accuracy_score(y_valid, y_valid_pred),2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log config, dataset and model to Etiq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For already trained models make sure you only you use a sample you held out. \n",
    "\n",
    "As you don't want any retraining of the model to occur, set your train_valid_test split to [0.0, 1.0, 0.0]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Created histogram summary of data (15 fields)\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Computed acurracy metrics for the dataset {'accuracy': 0.87, 'true_pos_rate': 0.6717687074829932, 'true_neg_rate': 0.9385279050957132}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Issue Aggregate = {'accuracy_below_threshold': IssueAggregate(name='accuracy_below_threshold', metric=<compiled_function accuracy at 0x14ee37f10>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_pos_rate_below_threshold': IssueAggregate(name='true_pos_rate_below_threshold', metric=<compiled_function true_pos_rate at 0x14eeec040>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_neg_rate_below_threshold': IssueAggregate(name='true_neg_rate_below_threshold', metric=<compiled_function true_neg_rate at 0x14eeec130>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0))}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Threshold (0.8, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0517:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b8ab9_row0_col0, #T_b8ab9_row1_col0, #T_b8ab9_row2_col0 {\n",
       "  background-color: #BAFFC9;\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "}\n",
       "#T_b8ab9_row0_col1, #T_b8ab9_row0_col2, #T_b8ab9_row0_col3, #T_b8ab9_row0_col4, #T_b8ab9_row0_col5, #T_b8ab9_row0_col6, #T_b8ab9_row0_col7, #T_b8ab9_row1_col1, #T_b8ab9_row1_col2, #T_b8ab9_row1_col3, #T_b8ab9_row1_col4, #T_b8ab9_row1_col5, #T_b8ab9_row1_col6, #T_b8ab9_row1_col7, #T_b8ab9_row2_col1, #T_b8ab9_row2_col2, #T_b8ab9_row2_col3, #T_b8ab9_row2_col4, #T_b8ab9_row2_col5, #T_b8ab9_row2_col6, #T_b8ab9_row2_col7 {\n",
       "  background-color: #BAFFC9;\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b8ab9\">\n",
       "  <caption>Issues Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b8ab9_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_b8ab9_level0_col1\" class=\"col_heading level0 col1\" >metric</th>\n",
       "      <th id=\"T_b8ab9_level0_col2\" class=\"col_heading level0 col2\" >measure</th>\n",
       "      <th id=\"T_b8ab9_level0_col3\" class=\"col_heading level0 col3\" >features</th>\n",
       "      <th id=\"T_b8ab9_level0_col4\" class=\"col_heading level0 col4\" >segments</th>\n",
       "      <th id=\"T_b8ab9_level0_col5\" class=\"col_heading level0 col5\" >total_issues_tested</th>\n",
       "      <th id=\"T_b8ab9_level0_col6\" class=\"col_heading level0 col6\" >issues_found</th>\n",
       "      <th id=\"T_b8ab9_level0_col7\" class=\"col_heading level0 col7\" >threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b8ab9_row0_col0\" class=\"data row0 col0\" >accuracy_below_threshold</td>\n",
       "      <td id=\"T_b8ab9_row0_col1\" class=\"data row0 col1\" >accuracy</td>\n",
       "      <td id=\"T_b8ab9_row0_col2\" class=\"data row0 col2\" >None</td>\n",
       "      <td id=\"T_b8ab9_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_b8ab9_row0_col4\" class=\"data row0 col4\" >None</td>\n",
       "      <td id=\"T_b8ab9_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_b8ab9_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_b8ab9_row0_col7\" class=\"data row0 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b8ab9_row1_col0\" class=\"data row1 col0\" >true_pos_rate_below_threshold</td>\n",
       "      <td id=\"T_b8ab9_row1_col1\" class=\"data row1 col1\" >true_pos_rate</td>\n",
       "      <td id=\"T_b8ab9_row1_col2\" class=\"data row1 col2\" >None</td>\n",
       "      <td id=\"T_b8ab9_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_b8ab9_row1_col4\" class=\"data row1 col4\" >None</td>\n",
       "      <td id=\"T_b8ab9_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "      <td id=\"T_b8ab9_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "      <td id=\"T_b8ab9_row1_col7\" class=\"data row1 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b8ab9_row2_col0\" class=\"data row2 col0\" >true_neg_rate_below_threshold</td>\n",
       "      <td id=\"T_b8ab9_row2_col1\" class=\"data row2 col1\" >true_neg_rate</td>\n",
       "      <td id=\"T_b8ab9_row2_col2\" class=\"data row2 col2\" >None</td>\n",
       "      <td id=\"T_b8ab9_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_b8ab9_row2_col4\" class=\"data row2 col4\" >None</td>\n",
       "      <td id=\"T_b8ab9_row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "      <td id=\"T_b8ab9_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_b8ab9_row2_col7\" class=\"data row2 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1504d6770>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import Model\n",
    "\n",
    "with etiq.etiq_config('config_already_trained_accuracy.json'):\n",
    "    #load your dataset\n",
    "\n",
    "    dataset = etiq.BiasDatasetBuilder.dataset(test)\n",
    "\n",
    "    #Log your already trained model\n",
    "    model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "    # Creating a snapshot\n",
    "    snapshot = project.snapshots.create(name=\"Snapshot 2\", \n",
    "                                    dataset=dataset, \n",
    "                                    model=model, \n",
    "                                    bias_params=etiq.biasparams.BiasParams(protected='gender', privileged=1, unprivileged=0, positive_outcome_label=1, negative_outcome_label=0))\n",
    "    \n",
    "    #accuracy metrics scan\n",
    "    (segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()\n",
    "    \n",
    "#issue_summary\n",
    "\n",
    "issue_summary.style.pipe(issue_summary_pretty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNAPSHOT 3, in-production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, functionality will not allow us to record actuals separately, but we are working on it. \n",
    "This means that to run scans which use the actuals (accuracy, a good chunk of the bias metrics scans, target and concept drift), you will have to create your dataset to include the actuals. To log it to etiq the actual will be the 'label' parameter in your config.\n",
    " \n",
    "This example is just for illustration purposes, as you will not be running production scans from a jupyter notebook. \n",
    "Etiq can be used with orchestration and model registry tools. Please email us: info@etiq.ai for help with using Etiq with your toolset and for online models. We will be adding demos on how to use Etiq with Airflow and MLflow shortly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log dataset, comparison dataset, model, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset we will use yesterday and today's datasets set-up earlier in the notebook, but any time window will work - depends on your scoring frequency. \n",
    "\n",
    "For model: we will use the model we've trained at the previous step. \n",
    "\n",
    "For config we will use a config that has scans achievable in production without the actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:etiq.charting:Created histogram summary of data (15 fields)\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Warning: potential data leak. You are evaluating a fitted model. If you use the same dataset that you used to train the model and you pass on just the training/validation/test split without passing on which was your validation dataset when you fitted the model, some observations that were previously in train can now be in test - which can skew your results\n",
      "WARNING:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Etiq removed the column encoding the protected attribute values from the dataset. The models are fitted and metrics are computed on a dataset without the protected attribute column. The protected attribute values can be found in the protected_train or protected_valid fields of each dataset\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Starting pipeline\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Computed acurracy metrics for the dataset {'accuracy': 0.9, 'true_pos_rate': 0.7065115085137332, 'true_neg_rate': 0.9549185843089759}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Issue Aggregate = {'accuracy_below_threshold': IssueAggregate(name='accuracy_below_threshold', metric=<compiled_function accuracy at 0x14ee37f10>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_pos_rate_below_threshold': IssueAggregate(name='true_pos_rate_below_threshold', metric=<compiled_function true_pos_rate at 0x14eeec040>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0)), 'true_neg_rate_below_threshold': IssueAggregate(name='true_neg_rate_below_threshold', metric=<compiled_function true_neg_rate at 0x14eeec130>, measure=None, features=set(), segments=set(), total_issues_tested=0, issues_found=0, threshold=(0.0, 1.0))}\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Threshold (0.8, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Threshold (0.6, 1.0)\n",
      "INFO:etiq.pipeline.AccuracyMetricsIssuePipeline0440:Completed pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eb3db_row0_col0, #T_eb3db_row1_col0, #T_eb3db_row2_col0 {\n",
       "  background-color: #BAFFC9;\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "}\n",
       "#T_eb3db_row0_col1, #T_eb3db_row0_col2, #T_eb3db_row0_col3, #T_eb3db_row0_col4, #T_eb3db_row0_col5, #T_eb3db_row0_col6, #T_eb3db_row0_col7, #T_eb3db_row1_col1, #T_eb3db_row1_col2, #T_eb3db_row1_col3, #T_eb3db_row1_col4, #T_eb3db_row1_col5, #T_eb3db_row1_col6, #T_eb3db_row1_col7, #T_eb3db_row2_col1, #T_eb3db_row2_col2, #T_eb3db_row2_col3, #T_eb3db_row2_col4, #T_eb3db_row2_col5, #T_eb3db_row2_col6, #T_eb3db_row2_col7 {\n",
       "  background-color: #BAFFC9;\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eb3db\">\n",
       "  <caption>Issues Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_eb3db_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_eb3db_level0_col1\" class=\"col_heading level0 col1\" >metric</th>\n",
       "      <th id=\"T_eb3db_level0_col2\" class=\"col_heading level0 col2\" >measure</th>\n",
       "      <th id=\"T_eb3db_level0_col3\" class=\"col_heading level0 col3\" >features</th>\n",
       "      <th id=\"T_eb3db_level0_col4\" class=\"col_heading level0 col4\" >segments</th>\n",
       "      <th id=\"T_eb3db_level0_col5\" class=\"col_heading level0 col5\" >total_issues_tested</th>\n",
       "      <th id=\"T_eb3db_level0_col6\" class=\"col_heading level0 col6\" >issues_found</th>\n",
       "      <th id=\"T_eb3db_level0_col7\" class=\"col_heading level0 col7\" >threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_eb3db_row0_col0\" class=\"data row0 col0\" >accuracy_below_threshold</td>\n",
       "      <td id=\"T_eb3db_row0_col1\" class=\"data row0 col1\" >accuracy</td>\n",
       "      <td id=\"T_eb3db_row0_col2\" class=\"data row0 col2\" >None</td>\n",
       "      <td id=\"T_eb3db_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_eb3db_row0_col4\" class=\"data row0 col4\" >None</td>\n",
       "      <td id=\"T_eb3db_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_eb3db_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_eb3db_row0_col7\" class=\"data row0 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb3db_row1_col0\" class=\"data row1 col0\" >true_pos_rate_below_threshold</td>\n",
       "      <td id=\"T_eb3db_row1_col1\" class=\"data row1 col1\" >true_pos_rate</td>\n",
       "      <td id=\"T_eb3db_row1_col2\" class=\"data row1 col2\" >None</td>\n",
       "      <td id=\"T_eb3db_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_eb3db_row1_col4\" class=\"data row1 col4\" >None</td>\n",
       "      <td id=\"T_eb3db_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "      <td id=\"T_eb3db_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "      <td id=\"T_eb3db_row1_col7\" class=\"data row1 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb3db_row2_col0\" class=\"data row2 col0\" >true_neg_rate_below_threshold</td>\n",
       "      <td id=\"T_eb3db_row2_col1\" class=\"data row2 col1\" >true_neg_rate</td>\n",
       "      <td id=\"T_eb3db_row2_col2\" class=\"data row2 col2\" >None</td>\n",
       "      <td id=\"T_eb3db_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_eb3db_row2_col4\" class=\"data row2 col4\" >None</td>\n",
       "      <td id=\"T_eb3db_row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "      <td id=\"T_eb3db_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_eb3db_row2_col7\" class=\"data row2 col7\" >0.6 - 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1500e2050>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from etiq import Model\n",
    "from etiq import SnapshotStage\n",
    "\n",
    "with etiq.etiq_config('config_production_accuracy.json'):\n",
    "    #load your dataset\n",
    "    dataset = etiq.BiasDatasetBuilder.dataset(data_encoded)\n",
    "\n",
    "    # Use the already trained model from the previous step\n",
    "    model = Model(model_architecture=standard_model, model_fitted=model_fit)\n",
    "\n",
    "    # Creating a snapshot, label it as PRODUCTION (snapshots are labelled Pre-Production) by default\n",
    "    snapshot = project.snapshots.create(name=\"Snapshot 3\", \n",
    "                                        dataset=dataset, \n",
    "                                        model=model,\n",
    "                                        bias_params=etiq.biasparams.BiasParams(protected='gender', privileged=1, unprivileged=0, positive_outcome_label=1, negative_outcome_label=0), \n",
    "                                        stage=SnapshotStage.PRODUCTION)\n",
    "\n",
    "    #accuracy metrics scan\n",
    "    (segments, issues, issue_summary) = snapshot.scan_accuracy_metrics()\n",
    "   \n",
    "# issue_summary\n",
    "\n",
    "issue_summary.style.pipe(issue_summary_pretty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etiq-1.3.7.1",
   "language": "python",
   "name": "etiq-1.3.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f73d2918ef91b3de9bdb310b3a78ccab2f85746153637654c892175835a3eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
